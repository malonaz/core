// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.9
// 	protoc        v6.30.0
// source: malonaz/ai/v1/metrics.proto

package v1

import (
	_ "google.golang.org/genproto/googleapis/api/annotations"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	durationpb "google.golang.org/protobuf/types/known/durationpb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Tracks metrics for an AI call.
type GenerationMetrics struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Time to first byte.
	// If empty, indicates that this was not streamed so it's equal to ttlb.
	Ttfb *durationpb.Duration `protobuf:"bytes,1,opt,name=ttfb,proto3" json:"ttfb,omitempty"`
	// Time to last byte.
	Ttlb          *durationpb.Duration `protobuf:"bytes,2,opt,name=ttlb,proto3" json:"ttlb,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *GenerationMetrics) Reset() {
	*x = GenerationMetrics{}
	mi := &file_malonaz_ai_v1_metrics_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *GenerationMetrics) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*GenerationMetrics) ProtoMessage() {}

func (x *GenerationMetrics) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_v1_metrics_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use GenerationMetrics.ProtoReflect.Descriptor instead.
func (*GenerationMetrics) Descriptor() ([]byte, []int) {
	return file_malonaz_ai_v1_metrics_proto_rawDescGZIP(), []int{0}
}

func (x *GenerationMetrics) GetTtfb() *durationpb.Duration {
	if x != nil {
		return x.Ttfb
	}
	return nil
}

func (x *GenerationMetrics) GetTtlb() *durationpb.Duration {
	if x != nil {
		return x.Ttlb
	}
	return nil
}

// Tracks model usage. When streamed out, incremental resource consumptions can be streamed out.
// The absolute truth for a resource consumption is the last one streamed out for this resource consumption.
type ModelUsage struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The resource name of the model used.
	// Format: providers/{provider}/models/{model}
	Model string `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	// Input token usage.
	InputToken *ResourceConsumption `protobuf:"bytes,2,opt,name=input_token,json=inputToken,proto3" json:"input_token,omitempty"`
	// Output token usage.
	OutputToken *ResourceConsumption `protobuf:"bytes,3,opt,name=output_token,json=outputToken,proto3" json:"output_token,omitempty"`
	// Output reasoning token usage.
	OutputReasoningToken *ResourceConsumption `protobuf:"bytes,4,opt,name=output_reasoning_token,json=outputReasoningToken,proto3" json:"output_reasoning_token,omitempty"`
	// Cache read token usage.
	InputCacheReadToken *ResourceConsumption `protobuf:"bytes,5,opt,name=input_cache_read_token,json=inputCacheReadToken,proto3" json:"input_cache_read_token,omitempty"`
	// Cache write token usage.
	InputCacheWriteToken *ResourceConsumption `protobuf:"bytes,6,opt,name=input_cache_write_token,json=inputCacheWriteToken,proto3" json:"input_cache_write_token,omitempty"`
	// Input seconds.
	InputSecond *ResourceConsumption `protobuf:"bytes,7,opt,name=input_second,json=inputSecond,proto3" json:"input_second,omitempty"`
	// Output seconds.
	OutputSecond *ResourceConsumption `protobuf:"bytes,8,opt,name=output_second,json=outputSecond,proto3" json:"output_second,omitempty"`
	// Input characters.
	InputCharacter *ResourceConsumption `protobuf:"bytes,9,opt,name=input_character,json=inputCharacter,proto3" json:"input_character,omitempty"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *ModelUsage) Reset() {
	*x = ModelUsage{}
	mi := &file_malonaz_ai_v1_metrics_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelUsage) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelUsage) ProtoMessage() {}

func (x *ModelUsage) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_v1_metrics_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelUsage.ProtoReflect.Descriptor instead.
func (*ModelUsage) Descriptor() ([]byte, []int) {
	return file_malonaz_ai_v1_metrics_proto_rawDescGZIP(), []int{1}
}

func (x *ModelUsage) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *ModelUsage) GetInputToken() *ResourceConsumption {
	if x != nil {
		return x.InputToken
	}
	return nil
}

func (x *ModelUsage) GetOutputToken() *ResourceConsumption {
	if x != nil {
		return x.OutputToken
	}
	return nil
}

func (x *ModelUsage) GetOutputReasoningToken() *ResourceConsumption {
	if x != nil {
		return x.OutputReasoningToken
	}
	return nil
}

func (x *ModelUsage) GetInputCacheReadToken() *ResourceConsumption {
	if x != nil {
		return x.InputCacheReadToken
	}
	return nil
}

func (x *ModelUsage) GetInputCacheWriteToken() *ResourceConsumption {
	if x != nil {
		return x.InputCacheWriteToken
	}
	return nil
}

func (x *ModelUsage) GetInputSecond() *ResourceConsumption {
	if x != nil {
		return x.InputSecond
	}
	return nil
}

func (x *ModelUsage) GetOutputSecond() *ResourceConsumption {
	if x != nil {
		return x.OutputSecond
	}
	return nil
}

func (x *ModelUsage) GetInputCharacter() *ResourceConsumption {
	if x != nil {
		return x.InputCharacter
	}
	return nil
}

// Tracks a particular resource consumption.
type ResourceConsumption struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Number of units consumed.
	Quantity int32 `protobuf:"varint,1,opt,name=quantity,proto3" json:"quantity,omitempty"`
	// Price in dollars for this resource consumption.
	Price         float64 `protobuf:"fixed64,2,opt,name=price,proto3" json:"price,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ResourceConsumption) Reset() {
	*x = ResourceConsumption{}
	mi := &file_malonaz_ai_v1_metrics_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ResourceConsumption) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ResourceConsumption) ProtoMessage() {}

func (x *ResourceConsumption) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_v1_metrics_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ResourceConsumption.ProtoReflect.Descriptor instead.
func (*ResourceConsumption) Descriptor() ([]byte, []int) {
	return file_malonaz_ai_v1_metrics_proto_rawDescGZIP(), []int{2}
}

func (x *ResourceConsumption) GetQuantity() int32 {
	if x != nil {
		return x.Quantity
	}
	return 0
}

func (x *ResourceConsumption) GetPrice() float64 {
	if x != nil {
		return x.Price
	}
	return 0
}

var File_malonaz_ai_v1_metrics_proto protoreflect.FileDescriptor

const file_malonaz_ai_v1_metrics_proto_rawDesc = "" +
	"\n" +
	"\x1bmalonaz/ai/v1/metrics.proto\x12\rmalonaz.ai.v1\x1a\x19google/api/resource.proto\x1a\x1egoogle/protobuf/duration.proto\"q\n" +
	"\x11GenerationMetrics\x12-\n" +
	"\x04ttfb\x18\x01 \x01(\v2\x19.google.protobuf.DurationR\x04ttfb\x12-\n" +
	"\x04ttlb\x18\x02 \x01(\v2\x19.google.protobuf.DurationR\x04ttlb\"\xb4\x05\n" +
	"\n" +
	"ModelUsage\x12/\n" +
	"\x05model\x18\x01 \x01(\tB\x19\xfaA\x16\n" +
	"\x14ai.malonaz.com/ModelR\x05model\x12C\n" +
	"\vinput_token\x18\x02 \x01(\v2\".malonaz.ai.v1.ResourceConsumptionR\n" +
	"inputToken\x12E\n" +
	"\foutput_token\x18\x03 \x01(\v2\".malonaz.ai.v1.ResourceConsumptionR\voutputToken\x12X\n" +
	"\x16output_reasoning_token\x18\x04 \x01(\v2\".malonaz.ai.v1.ResourceConsumptionR\x14outputReasoningToken\x12W\n" +
	"\x16input_cache_read_token\x18\x05 \x01(\v2\".malonaz.ai.v1.ResourceConsumptionR\x13inputCacheReadToken\x12Y\n" +
	"\x17input_cache_write_token\x18\x06 \x01(\v2\".malonaz.ai.v1.ResourceConsumptionR\x14inputCacheWriteToken\x12E\n" +
	"\finput_second\x18\a \x01(\v2\".malonaz.ai.v1.ResourceConsumptionR\vinputSecond\x12G\n" +
	"\routput_second\x18\b \x01(\v2\".malonaz.ai.v1.ResourceConsumptionR\foutputSecond\x12K\n" +
	"\x0finput_character\x18\t \x01(\v2\".malonaz.ai.v1.ResourceConsumptionR\x0einputCharacter\"G\n" +
	"\x13ResourceConsumption\x12\x1a\n" +
	"\bquantity\x18\x01 \x01(\x05R\bquantity\x12\x14\n" +
	"\x05price\x18\x02 \x01(\x01R\x05priceB(Z&github.com/malonaz/core/genproto/ai/v1b\x06proto3"

var (
	file_malonaz_ai_v1_metrics_proto_rawDescOnce sync.Once
	file_malonaz_ai_v1_metrics_proto_rawDescData []byte
)

func file_malonaz_ai_v1_metrics_proto_rawDescGZIP() []byte {
	file_malonaz_ai_v1_metrics_proto_rawDescOnce.Do(func() {
		file_malonaz_ai_v1_metrics_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_malonaz_ai_v1_metrics_proto_rawDesc), len(file_malonaz_ai_v1_metrics_proto_rawDesc)))
	})
	return file_malonaz_ai_v1_metrics_proto_rawDescData
}

var file_malonaz_ai_v1_metrics_proto_msgTypes = make([]protoimpl.MessageInfo, 3)
var file_malonaz_ai_v1_metrics_proto_goTypes = []any{
	(*GenerationMetrics)(nil),   // 0: malonaz.ai.v1.GenerationMetrics
	(*ModelUsage)(nil),          // 1: malonaz.ai.v1.ModelUsage
	(*ResourceConsumption)(nil), // 2: malonaz.ai.v1.ResourceConsumption
	(*durationpb.Duration)(nil), // 3: google.protobuf.Duration
}
var file_malonaz_ai_v1_metrics_proto_depIdxs = []int32{
	3,  // 0: malonaz.ai.v1.GenerationMetrics.ttfb:type_name -> google.protobuf.Duration
	3,  // 1: malonaz.ai.v1.GenerationMetrics.ttlb:type_name -> google.protobuf.Duration
	2,  // 2: malonaz.ai.v1.ModelUsage.input_token:type_name -> malonaz.ai.v1.ResourceConsumption
	2,  // 3: malonaz.ai.v1.ModelUsage.output_token:type_name -> malonaz.ai.v1.ResourceConsumption
	2,  // 4: malonaz.ai.v1.ModelUsage.output_reasoning_token:type_name -> malonaz.ai.v1.ResourceConsumption
	2,  // 5: malonaz.ai.v1.ModelUsage.input_cache_read_token:type_name -> malonaz.ai.v1.ResourceConsumption
	2,  // 6: malonaz.ai.v1.ModelUsage.input_cache_write_token:type_name -> malonaz.ai.v1.ResourceConsumption
	2,  // 7: malonaz.ai.v1.ModelUsage.input_second:type_name -> malonaz.ai.v1.ResourceConsumption
	2,  // 8: malonaz.ai.v1.ModelUsage.output_second:type_name -> malonaz.ai.v1.ResourceConsumption
	2,  // 9: malonaz.ai.v1.ModelUsage.input_character:type_name -> malonaz.ai.v1.ResourceConsumption
	10, // [10:10] is the sub-list for method output_type
	10, // [10:10] is the sub-list for method input_type
	10, // [10:10] is the sub-list for extension type_name
	10, // [10:10] is the sub-list for extension extendee
	0,  // [0:10] is the sub-list for field type_name
}

func init() { file_malonaz_ai_v1_metrics_proto_init() }
func file_malonaz_ai_v1_metrics_proto_init() {
	if File_malonaz_ai_v1_metrics_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_malonaz_ai_v1_metrics_proto_rawDesc), len(file_malonaz_ai_v1_metrics_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   3,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_malonaz_ai_v1_metrics_proto_goTypes,
		DependencyIndexes: file_malonaz_ai_v1_metrics_proto_depIdxs,
		MessageInfos:      file_malonaz_ai_v1_metrics_proto_msgTypes,
	}.Build()
	File_malonaz_ai_v1_metrics_proto = out.File
	file_malonaz_ai_v1_metrics_proto_goTypes = nil
	file_malonaz_ai_v1_metrics_proto_depIdxs = nil
}
