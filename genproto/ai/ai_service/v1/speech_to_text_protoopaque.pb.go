// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.9
// 	protoc        v6.32.1
// source: malonaz/ai/ai_service/v1/speech_to_text.proto

//go:build protoopaque

package v1

import (
	_ "buf.build/gen/go/bufbuild/protovalidate/protocolbuffers/go/buf/validate"
	v11 "github.com/malonaz/core/genproto/ai/v1"
	v1 "github.com/malonaz/core/genproto/audio/v1"
	_ "google.golang.org/genproto/googleapis/api/annotations"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	durationpb "google.golang.org/protobuf/types/known/durationpb"
	reflect "reflect"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Request message for AiService.SpeechToText.
type SpeechToTextRequest struct {
	state                   protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_Model        string                 `protobuf:"bytes,1,opt,name=model,proto3"`
	xxx_hidden_AudioFormat  *v1.Format             `protobuf:"bytes,2,opt,name=audio_format,json=audioFormat,proto3"`
	xxx_hidden_AudioChunk   *v1.Chunk              `protobuf:"bytes,3,opt,name=audio_chunk,json=audioChunk,proto3"`
	xxx_hidden_LanguageCode string                 `protobuf:"bytes,4,opt,name=language_code,json=languageCode,proto3"`
	unknownFields           protoimpl.UnknownFields
	sizeCache               protoimpl.SizeCache
}

func (x *SpeechToTextRequest) Reset() {
	*x = SpeechToTextRequest{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextRequest) ProtoMessage() {}

func (x *SpeechToTextRequest) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextRequest) GetModel() string {
	if x != nil {
		return x.xxx_hidden_Model
	}
	return ""
}

func (x *SpeechToTextRequest) GetAudioFormat() *v1.Format {
	if x != nil {
		return x.xxx_hidden_AudioFormat
	}
	return nil
}

func (x *SpeechToTextRequest) GetAudioChunk() *v1.Chunk {
	if x != nil {
		return x.xxx_hidden_AudioChunk
	}
	return nil
}

func (x *SpeechToTextRequest) GetLanguageCode() string {
	if x != nil {
		return x.xxx_hidden_LanguageCode
	}
	return ""
}

func (x *SpeechToTextRequest) SetModel(v string) {
	x.xxx_hidden_Model = v
}

func (x *SpeechToTextRequest) SetAudioFormat(v *v1.Format) {
	x.xxx_hidden_AudioFormat = v
}

func (x *SpeechToTextRequest) SetAudioChunk(v *v1.Chunk) {
	x.xxx_hidden_AudioChunk = v
}

func (x *SpeechToTextRequest) SetLanguageCode(v string) {
	x.xxx_hidden_LanguageCode = v
}

func (x *SpeechToTextRequest) HasAudioFormat() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_AudioFormat != nil
}

func (x *SpeechToTextRequest) HasAudioChunk() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_AudioChunk != nil
}

func (x *SpeechToTextRequest) ClearAudioFormat() {
	x.xxx_hidden_AudioFormat = nil
}

func (x *SpeechToTextRequest) ClearAudioChunk() {
	x.xxx_hidden_AudioChunk = nil
}

type SpeechToTextRequest_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The resource name of the model used.
	// Format: providers/{provider}/models/{model}
	Model string
	// Audio format of the audio.
	AudioFormat *v1.Format
	// Audio to transcribe.
	AudioChunk *v1.Chunk
	// Optional language code to improve transcription accuracy (e.g., "en", "es").
	LanguageCode string
}

func (b0 SpeechToTextRequest_builder) Build() *SpeechToTextRequest {
	m0 := &SpeechToTextRequest{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Model = b.Model
	x.xxx_hidden_AudioFormat = b.AudioFormat
	x.xxx_hidden_AudioChunk = b.AudioChunk
	x.xxx_hidden_LanguageCode = b.LanguageCode
	return m0
}

// Response message for AiService.SpeechToText.
type SpeechToTextResponse struct {
	state                        protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_Transcript        string                 `protobuf:"bytes,1,opt,name=transcript,proto3"`
	xxx_hidden_ModelUsage        *v11.ModelUsage        `protobuf:"bytes,2,opt,name=model_usage,json=modelUsage,proto3"`
	xxx_hidden_GenerationMetrics *v11.GenerationMetrics `protobuf:"bytes,3,opt,name=generation_metrics,json=generationMetrics,proto3"`
	unknownFields                protoimpl.UnknownFields
	sizeCache                    protoimpl.SizeCache
}

func (x *SpeechToTextResponse) Reset() {
	*x = SpeechToTextResponse{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextResponse) ProtoMessage() {}

func (x *SpeechToTextResponse) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextResponse) GetTranscript() string {
	if x != nil {
		return x.xxx_hidden_Transcript
	}
	return ""
}

func (x *SpeechToTextResponse) GetModelUsage() *v11.ModelUsage {
	if x != nil {
		return x.xxx_hidden_ModelUsage
	}
	return nil
}

func (x *SpeechToTextResponse) GetGenerationMetrics() *v11.GenerationMetrics {
	if x != nil {
		return x.xxx_hidden_GenerationMetrics
	}
	return nil
}

func (x *SpeechToTextResponse) SetTranscript(v string) {
	x.xxx_hidden_Transcript = v
}

func (x *SpeechToTextResponse) SetModelUsage(v *v11.ModelUsage) {
	x.xxx_hidden_ModelUsage = v
}

func (x *SpeechToTextResponse) SetGenerationMetrics(v *v11.GenerationMetrics) {
	x.xxx_hidden_GenerationMetrics = v
}

func (x *SpeechToTextResponse) HasModelUsage() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_ModelUsage != nil
}

func (x *SpeechToTextResponse) HasGenerationMetrics() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_GenerationMetrics != nil
}

func (x *SpeechToTextResponse) ClearModelUsage() {
	x.xxx_hidden_ModelUsage = nil
}

func (x *SpeechToTextResponse) ClearGenerationMetrics() {
	x.xxx_hidden_GenerationMetrics = nil
}

type SpeechToTextResponse_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The transcribed text.
	Transcript string
	// Model usage metrics.
	ModelUsage *v11.ModelUsage
	// Generation metrics.
	GenerationMetrics *v11.GenerationMetrics
}

func (b0 SpeechToTextResponse_builder) Build() *SpeechToTextResponse {
	m0 := &SpeechToTextResponse{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Transcript = b.Transcript
	x.xxx_hidden_ModelUsage = b.ModelUsage
	x.xxx_hidden_GenerationMetrics = b.GenerationMetrics
	return m0
}

// Request message for AiService.SpeechToTextStream.
type SpeechToTextStreamRequest struct {
	state              protoimpl.MessageState              `protogen:"opaque.v1"`
	xxx_hidden_Content isSpeechToTextStreamRequest_Content `protobuf_oneof:"content"`
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *SpeechToTextStreamRequest) Reset() {
	*x = SpeechToTextStreamRequest{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextStreamRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextStreamRequest) ProtoMessage() {}

func (x *SpeechToTextStreamRequest) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextStreamRequest) GetConfiguration() *SpeechToTextStreamConfiguration {
	if x != nil {
		if x, ok := x.xxx_hidden_Content.(*speechToTextStreamRequest_Configuration); ok {
			return x.Configuration
		}
	}
	return nil
}

func (x *SpeechToTextStreamRequest) GetAudioChunk() *v1.Chunk {
	if x != nil {
		if x, ok := x.xxx_hidden_Content.(*speechToTextStreamRequest_AudioChunk); ok {
			return x.AudioChunk
		}
	}
	return nil
}

func (x *SpeechToTextStreamRequest) SetConfiguration(v *SpeechToTextStreamConfiguration) {
	if v == nil {
		x.xxx_hidden_Content = nil
		return
	}
	x.xxx_hidden_Content = &speechToTextStreamRequest_Configuration{v}
}

func (x *SpeechToTextStreamRequest) SetAudioChunk(v *v1.Chunk) {
	if v == nil {
		x.xxx_hidden_Content = nil
		return
	}
	x.xxx_hidden_Content = &speechToTextStreamRequest_AudioChunk{v}
}

func (x *SpeechToTextStreamRequest) HasContent() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_Content != nil
}

func (x *SpeechToTextStreamRequest) HasConfiguration() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Content.(*speechToTextStreamRequest_Configuration)
	return ok
}

func (x *SpeechToTextStreamRequest) HasAudioChunk() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Content.(*speechToTextStreamRequest_AudioChunk)
	return ok
}

func (x *SpeechToTextStreamRequest) ClearContent() {
	x.xxx_hidden_Content = nil
}

func (x *SpeechToTextStreamRequest) ClearConfiguration() {
	if _, ok := x.xxx_hidden_Content.(*speechToTextStreamRequest_Configuration); ok {
		x.xxx_hidden_Content = nil
	}
}

func (x *SpeechToTextStreamRequest) ClearAudioChunk() {
	if _, ok := x.xxx_hidden_Content.(*speechToTextStreamRequest_AudioChunk); ok {
		x.xxx_hidden_Content = nil
	}
}

const SpeechToTextStreamRequest_Content_not_set_case case_SpeechToTextStreamRequest_Content = 0
const SpeechToTextStreamRequest_Configuration_case case_SpeechToTextStreamRequest_Content = 1
const SpeechToTextStreamRequest_AudioChunk_case case_SpeechToTextStreamRequest_Content = 2

func (x *SpeechToTextStreamRequest) WhichContent() case_SpeechToTextStreamRequest_Content {
	if x == nil {
		return SpeechToTextStreamRequest_Content_not_set_case
	}
	switch x.xxx_hidden_Content.(type) {
	case *speechToTextStreamRequest_Configuration:
		return SpeechToTextStreamRequest_Configuration_case
	case *speechToTextStreamRequest_AudioChunk:
		return SpeechToTextStreamRequest_AudioChunk_case
	default:
		return SpeechToTextStreamRequest_Content_not_set_case
	}
}

type SpeechToTextStreamRequest_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// Content of this request.

	// Fields of oneof xxx_hidden_Content:
	// Configuration for the stream. Must be sent first.
	Configuration *SpeechToTextStreamConfiguration
	// Audio data chunk.
	AudioChunk *v1.Chunk
	// -- end of xxx_hidden_Content
}

func (b0 SpeechToTextStreamRequest_builder) Build() *SpeechToTextStreamRequest {
	m0 := &SpeechToTextStreamRequest{}
	b, x := &b0, m0
	_, _ = b, x
	if b.Configuration != nil {
		x.xxx_hidden_Content = &speechToTextStreamRequest_Configuration{b.Configuration}
	}
	if b.AudioChunk != nil {
		x.xxx_hidden_Content = &speechToTextStreamRequest_AudioChunk{b.AudioChunk}
	}
	return m0
}

type case_SpeechToTextStreamRequest_Content protoreflect.FieldNumber

func (x case_SpeechToTextStreamRequest_Content) String() string {
	md := file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[2].Descriptor()
	if x == 0 {
		return "not set"
	}
	return protoimpl.X.MessageFieldStringOf(md, protoreflect.FieldNumber(x))
}

type isSpeechToTextStreamRequest_Content interface {
	isSpeechToTextStreamRequest_Content()
}

type speechToTextStreamRequest_Configuration struct {
	// Configuration for the stream. Must be sent first.
	Configuration *SpeechToTextStreamConfiguration `protobuf:"bytes,1,opt,name=configuration,proto3,oneof"`
}

type speechToTextStreamRequest_AudioChunk struct {
	// Audio data chunk.
	AudioChunk *v1.Chunk `protobuf:"bytes,2,opt,name=audio_chunk,json=audioChunk,proto3,oneof"`
}

func (*speechToTextStreamRequest_Configuration) isSpeechToTextStreamRequest_Content() {}

func (*speechToTextStreamRequest_AudioChunk) isSpeechToTextStreamRequest_Content() {}

// Configuration for speech to text streaming. Sent as the first message.
type SpeechToTextStreamConfiguration struct {
	state                                        protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_Model                             string                 `protobuf:"bytes,1,opt,name=model,proto3"`
	xxx_hidden_AudioFormat                       *v1.Format             `protobuf:"bytes,2,opt,name=audio_format,json=audioFormat,proto3"`
	xxx_hidden_EndOfTurnConfidenceThreshold      float64                `protobuf:"fixed64,3,opt,name=end_of_turn_confidence_threshold,json=endOfTurnConfidenceThreshold,proto3"`
	xxx_hidden_EagerEndOfTurnConfidenceThreshold float64                `protobuf:"fixed64,4,opt,name=eager_end_of_turn_confidence_threshold,json=eagerEndOfTurnConfidenceThreshold,proto3"`
	xxx_hidden_EndOfTurnTimeout                  *durationpb.Duration   `protobuf:"bytes,5,opt,name=end_of_turn_timeout,json=endOfTurnTimeout,proto3"`
	xxx_hidden_LanguageCode                      string                 `protobuf:"bytes,6,opt,name=language_code,json=languageCode,proto3"`
	unknownFields                                protoimpl.UnknownFields
	sizeCache                                    protoimpl.SizeCache
}

func (x *SpeechToTextStreamConfiguration) Reset() {
	*x = SpeechToTextStreamConfiguration{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextStreamConfiguration) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextStreamConfiguration) ProtoMessage() {}

func (x *SpeechToTextStreamConfiguration) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextStreamConfiguration) GetModel() string {
	if x != nil {
		return x.xxx_hidden_Model
	}
	return ""
}

func (x *SpeechToTextStreamConfiguration) GetAudioFormat() *v1.Format {
	if x != nil {
		return x.xxx_hidden_AudioFormat
	}
	return nil
}

func (x *SpeechToTextStreamConfiguration) GetEndOfTurnConfidenceThreshold() float64 {
	if x != nil {
		return x.xxx_hidden_EndOfTurnConfidenceThreshold
	}
	return 0
}

func (x *SpeechToTextStreamConfiguration) GetEagerEndOfTurnConfidenceThreshold() float64 {
	if x != nil {
		return x.xxx_hidden_EagerEndOfTurnConfidenceThreshold
	}
	return 0
}

func (x *SpeechToTextStreamConfiguration) GetEndOfTurnTimeout() *durationpb.Duration {
	if x != nil {
		return x.xxx_hidden_EndOfTurnTimeout
	}
	return nil
}

func (x *SpeechToTextStreamConfiguration) GetLanguageCode() string {
	if x != nil {
		return x.xxx_hidden_LanguageCode
	}
	return ""
}

func (x *SpeechToTextStreamConfiguration) SetModel(v string) {
	x.xxx_hidden_Model = v
}

func (x *SpeechToTextStreamConfiguration) SetAudioFormat(v *v1.Format) {
	x.xxx_hidden_AudioFormat = v
}

func (x *SpeechToTextStreamConfiguration) SetEndOfTurnConfidenceThreshold(v float64) {
	x.xxx_hidden_EndOfTurnConfidenceThreshold = v
}

func (x *SpeechToTextStreamConfiguration) SetEagerEndOfTurnConfidenceThreshold(v float64) {
	x.xxx_hidden_EagerEndOfTurnConfidenceThreshold = v
}

func (x *SpeechToTextStreamConfiguration) SetEndOfTurnTimeout(v *durationpb.Duration) {
	x.xxx_hidden_EndOfTurnTimeout = v
}

func (x *SpeechToTextStreamConfiguration) SetLanguageCode(v string) {
	x.xxx_hidden_LanguageCode = v
}

func (x *SpeechToTextStreamConfiguration) HasAudioFormat() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_AudioFormat != nil
}

func (x *SpeechToTextStreamConfiguration) HasEndOfTurnTimeout() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_EndOfTurnTimeout != nil
}

func (x *SpeechToTextStreamConfiguration) ClearAudioFormat() {
	x.xxx_hidden_AudioFormat = nil
}

func (x *SpeechToTextStreamConfiguration) ClearEndOfTurnTimeout() {
	x.xxx_hidden_EndOfTurnTimeout = nil
}

type SpeechToTextStreamConfiguration_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The resource name of the model used.
	// Format: providers/{provider}/models/{model}
	Model string
	// Audio format of the audio stream.
	AudioFormat *v1.Format
	// End of turn confidence threshold.
	EndOfTurnConfidenceThreshold float64
	// Eager end of turn confidence threshold (must be <= `end_of_turn_threshold`).
	EagerEndOfTurnConfidenceThreshold float64
	// Maximum silence duration before forcing an end of turn, regardless of confidence, after a turn has started.
	// - Use 3000-4000 for rapid-response environments.
	// - Use 7000-1000 for users with frequent pauses.
	EndOfTurnTimeout *durationpb.Duration
	// Optional language code to improve transcription accuracy (e.g., "en", "es").
	LanguageCode string
}

func (b0 SpeechToTextStreamConfiguration_builder) Build() *SpeechToTextStreamConfiguration {
	m0 := &SpeechToTextStreamConfiguration{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_Model = b.Model
	x.xxx_hidden_AudioFormat = b.AudioFormat
	x.xxx_hidden_EndOfTurnConfidenceThreshold = b.EndOfTurnConfidenceThreshold
	x.xxx_hidden_EagerEndOfTurnConfidenceThreshold = b.EagerEndOfTurnConfidenceThreshold
	x.xxx_hidden_EndOfTurnTimeout = b.EndOfTurnTimeout
	x.xxx_hidden_LanguageCode = b.LanguageCode
	return m0
}

// Response message for AiService.SpeechToTextStream.
type SpeechToTextStreamResponse struct {
	state              protoimpl.MessageState               `protogen:"opaque.v1"`
	xxx_hidden_Content isSpeechToTextStreamResponse_Content `protobuf_oneof:"content"`
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *SpeechToTextStreamResponse) Reset() {
	*x = SpeechToTextStreamResponse{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextStreamResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextStreamResponse) ProtoMessage() {}

func (x *SpeechToTextStreamResponse) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextStreamResponse) GetTurnStart() *SpeechToTextStreamTurnEvent {
	if x != nil {
		if x, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnStart); ok {
			return x.TurnStart
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetTurnUpdate() *SpeechToTextStreamTurnEvent {
	if x != nil {
		if x, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnUpdate); ok {
			return x.TurnUpdate
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetTurnEagerEnd() *SpeechToTextStreamTurnEvent {
	if x != nil {
		if x, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnEagerEnd); ok {
			return x.TurnEagerEnd
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetTurnResumed() *SpeechToTextStreamTurnEvent {
	if x != nil {
		if x, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnResumed); ok {
			return x.TurnResumed
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetTurnEnd() *SpeechToTextStreamTurnEvent {
	if x != nil {
		if x, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnEnd); ok {
			return x.TurnEnd
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetModelUsage() *v11.ModelUsage {
	if x != nil {
		if x, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_ModelUsage); ok {
			return x.ModelUsage
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetGenerationMetrics() *v11.GenerationMetrics {
	if x != nil {
		if x, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_GenerationMetrics); ok {
			return x.GenerationMetrics
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) SetTurnStart(v *SpeechToTextStreamTurnEvent) {
	if v == nil {
		x.xxx_hidden_Content = nil
		return
	}
	x.xxx_hidden_Content = &speechToTextStreamResponse_TurnStart{v}
}

func (x *SpeechToTextStreamResponse) SetTurnUpdate(v *SpeechToTextStreamTurnEvent) {
	if v == nil {
		x.xxx_hidden_Content = nil
		return
	}
	x.xxx_hidden_Content = &speechToTextStreamResponse_TurnUpdate{v}
}

func (x *SpeechToTextStreamResponse) SetTurnEagerEnd(v *SpeechToTextStreamTurnEvent) {
	if v == nil {
		x.xxx_hidden_Content = nil
		return
	}
	x.xxx_hidden_Content = &speechToTextStreamResponse_TurnEagerEnd{v}
}

func (x *SpeechToTextStreamResponse) SetTurnResumed(v *SpeechToTextStreamTurnEvent) {
	if v == nil {
		x.xxx_hidden_Content = nil
		return
	}
	x.xxx_hidden_Content = &speechToTextStreamResponse_TurnResumed{v}
}

func (x *SpeechToTextStreamResponse) SetTurnEnd(v *SpeechToTextStreamTurnEvent) {
	if v == nil {
		x.xxx_hidden_Content = nil
		return
	}
	x.xxx_hidden_Content = &speechToTextStreamResponse_TurnEnd{v}
}

func (x *SpeechToTextStreamResponse) SetModelUsage(v *v11.ModelUsage) {
	if v == nil {
		x.xxx_hidden_Content = nil
		return
	}
	x.xxx_hidden_Content = &speechToTextStreamResponse_ModelUsage{v}
}

func (x *SpeechToTextStreamResponse) SetGenerationMetrics(v *v11.GenerationMetrics) {
	if v == nil {
		x.xxx_hidden_Content = nil
		return
	}
	x.xxx_hidden_Content = &speechToTextStreamResponse_GenerationMetrics{v}
}

func (x *SpeechToTextStreamResponse) HasContent() bool {
	if x == nil {
		return false
	}
	return x.xxx_hidden_Content != nil
}

func (x *SpeechToTextStreamResponse) HasTurnStart() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnStart)
	return ok
}

func (x *SpeechToTextStreamResponse) HasTurnUpdate() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnUpdate)
	return ok
}

func (x *SpeechToTextStreamResponse) HasTurnEagerEnd() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnEagerEnd)
	return ok
}

func (x *SpeechToTextStreamResponse) HasTurnResumed() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnResumed)
	return ok
}

func (x *SpeechToTextStreamResponse) HasTurnEnd() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnEnd)
	return ok
}

func (x *SpeechToTextStreamResponse) HasModelUsage() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_ModelUsage)
	return ok
}

func (x *SpeechToTextStreamResponse) HasGenerationMetrics() bool {
	if x == nil {
		return false
	}
	_, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_GenerationMetrics)
	return ok
}

func (x *SpeechToTextStreamResponse) ClearContent() {
	x.xxx_hidden_Content = nil
}

func (x *SpeechToTextStreamResponse) ClearTurnStart() {
	if _, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnStart); ok {
		x.xxx_hidden_Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearTurnUpdate() {
	if _, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnUpdate); ok {
		x.xxx_hidden_Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearTurnEagerEnd() {
	if _, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnEagerEnd); ok {
		x.xxx_hidden_Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearTurnResumed() {
	if _, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnResumed); ok {
		x.xxx_hidden_Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearTurnEnd() {
	if _, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_TurnEnd); ok {
		x.xxx_hidden_Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearModelUsage() {
	if _, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_ModelUsage); ok {
		x.xxx_hidden_Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearGenerationMetrics() {
	if _, ok := x.xxx_hidden_Content.(*speechToTextStreamResponse_GenerationMetrics); ok {
		x.xxx_hidden_Content = nil
	}
}

const SpeechToTextStreamResponse_Content_not_set_case case_SpeechToTextStreamResponse_Content = 0
const SpeechToTextStreamResponse_TurnStart_case case_SpeechToTextStreamResponse_Content = 1
const SpeechToTextStreamResponse_TurnUpdate_case case_SpeechToTextStreamResponse_Content = 2
const SpeechToTextStreamResponse_TurnEagerEnd_case case_SpeechToTextStreamResponse_Content = 3
const SpeechToTextStreamResponse_TurnResumed_case case_SpeechToTextStreamResponse_Content = 4
const SpeechToTextStreamResponse_TurnEnd_case case_SpeechToTextStreamResponse_Content = 5
const SpeechToTextStreamResponse_ModelUsage_case case_SpeechToTextStreamResponse_Content = 6
const SpeechToTextStreamResponse_GenerationMetrics_case case_SpeechToTextStreamResponse_Content = 7

func (x *SpeechToTextStreamResponse) WhichContent() case_SpeechToTextStreamResponse_Content {
	if x == nil {
		return SpeechToTextStreamResponse_Content_not_set_case
	}
	switch x.xxx_hidden_Content.(type) {
	case *speechToTextStreamResponse_TurnStart:
		return SpeechToTextStreamResponse_TurnStart_case
	case *speechToTextStreamResponse_TurnUpdate:
		return SpeechToTextStreamResponse_TurnUpdate_case
	case *speechToTextStreamResponse_TurnEagerEnd:
		return SpeechToTextStreamResponse_TurnEagerEnd_case
	case *speechToTextStreamResponse_TurnResumed:
		return SpeechToTextStreamResponse_TurnResumed_case
	case *speechToTextStreamResponse_TurnEnd:
		return SpeechToTextStreamResponse_TurnEnd_case
	case *speechToTextStreamResponse_ModelUsage:
		return SpeechToTextStreamResponse_ModelUsage_case
	case *speechToTextStreamResponse_GenerationMetrics:
		return SpeechToTextStreamResponse_GenerationMetrics_case
	default:
		return SpeechToTextStreamResponse_Content_not_set_case
	}
}

type SpeechToTextStreamResponse_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// Content of this response.

	// Fields of oneof xxx_hidden_Content:
	// Indicates the user has started speaking a new turn.
	TurnStart *SpeechToTextStreamTurnEvent
	// Provides a partial transcript update during an ongoing turn.
	TurnUpdate *SpeechToTextStreamTurnEvent
	// Indicates the model predicts the turn is likely ending (tentative, may be resumed).
	TurnEagerEnd *SpeechToTextStreamTurnEvent
	// Indicates a previously signaled eager end of turn was incorrect and the turn continues.
	TurnResumed *SpeechToTextStreamTurnEvent
	// Indicates the user's turn has definitively ended with a final transcript.
	TurnEnd *SpeechToTextStreamTurnEvent
	// Model usage metrics (sent at the end of the stream).
	ModelUsage *v11.ModelUsage
	// Generation metrics (sent at the end of the stream).
	GenerationMetrics *v11.GenerationMetrics
	// -- end of xxx_hidden_Content
}

func (b0 SpeechToTextStreamResponse_builder) Build() *SpeechToTextStreamResponse {
	m0 := &SpeechToTextStreamResponse{}
	b, x := &b0, m0
	_, _ = b, x
	if b.TurnStart != nil {
		x.xxx_hidden_Content = &speechToTextStreamResponse_TurnStart{b.TurnStart}
	}
	if b.TurnUpdate != nil {
		x.xxx_hidden_Content = &speechToTextStreamResponse_TurnUpdate{b.TurnUpdate}
	}
	if b.TurnEagerEnd != nil {
		x.xxx_hidden_Content = &speechToTextStreamResponse_TurnEagerEnd{b.TurnEagerEnd}
	}
	if b.TurnResumed != nil {
		x.xxx_hidden_Content = &speechToTextStreamResponse_TurnResumed{b.TurnResumed}
	}
	if b.TurnEnd != nil {
		x.xxx_hidden_Content = &speechToTextStreamResponse_TurnEnd{b.TurnEnd}
	}
	if b.ModelUsage != nil {
		x.xxx_hidden_Content = &speechToTextStreamResponse_ModelUsage{b.ModelUsage}
	}
	if b.GenerationMetrics != nil {
		x.xxx_hidden_Content = &speechToTextStreamResponse_GenerationMetrics{b.GenerationMetrics}
	}
	return m0
}

type case_SpeechToTextStreamResponse_Content protoreflect.FieldNumber

func (x case_SpeechToTextStreamResponse_Content) String() string {
	md := file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[4].Descriptor()
	if x == 0 {
		return "not set"
	}
	return protoimpl.X.MessageFieldStringOf(md, protoreflect.FieldNumber(x))
}

type isSpeechToTextStreamResponse_Content interface {
	isSpeechToTextStreamResponse_Content()
}

type speechToTextStreamResponse_TurnStart struct {
	// Indicates the user has started speaking a new turn.
	TurnStart *SpeechToTextStreamTurnEvent `protobuf:"bytes,1,opt,name=turn_start,json=turnStart,proto3,oneof"`
}

type speechToTextStreamResponse_TurnUpdate struct {
	// Provides a partial transcript update during an ongoing turn.
	TurnUpdate *SpeechToTextStreamTurnEvent `protobuf:"bytes,2,opt,name=turn_update,json=turnUpdate,proto3,oneof"`
}

type speechToTextStreamResponse_TurnEagerEnd struct {
	// Indicates the model predicts the turn is likely ending (tentative, may be resumed).
	TurnEagerEnd *SpeechToTextStreamTurnEvent `protobuf:"bytes,3,opt,name=turn_eager_end,json=turnEagerEnd,proto3,oneof"`
}

type speechToTextStreamResponse_TurnResumed struct {
	// Indicates a previously signaled eager end of turn was incorrect and the turn continues.
	TurnResumed *SpeechToTextStreamTurnEvent `protobuf:"bytes,4,opt,name=turn_resumed,json=turnResumed,proto3,oneof"`
}

type speechToTextStreamResponse_TurnEnd struct {
	// Indicates the user's turn has definitively ended with a final transcript.
	TurnEnd *SpeechToTextStreamTurnEvent `protobuf:"bytes,5,opt,name=turn_end,json=turnEnd,proto3,oneof"`
}

type speechToTextStreamResponse_ModelUsage struct {
	// Model usage metrics (sent at the end of the stream).
	ModelUsage *v11.ModelUsage `protobuf:"bytes,6,opt,name=model_usage,json=modelUsage,proto3,oneof"`
}

type speechToTextStreamResponse_GenerationMetrics struct {
	// Generation metrics (sent at the end of the stream).
	GenerationMetrics *v11.GenerationMetrics `protobuf:"bytes,7,opt,name=generation_metrics,json=generationMetrics,proto3,oneof"`
}

func (*speechToTextStreamResponse_TurnStart) isSpeechToTextStreamResponse_Content() {}

func (*speechToTextStreamResponse_TurnUpdate) isSpeechToTextStreamResponse_Content() {}

func (*speechToTextStreamResponse_TurnEagerEnd) isSpeechToTextStreamResponse_Content() {}

func (*speechToTextStreamResponse_TurnResumed) isSpeechToTextStreamResponse_Content() {}

func (*speechToTextStreamResponse_TurnEnd) isSpeechToTextStreamResponse_Content() {}

func (*speechToTextStreamResponse_ModelUsage) isSpeechToTextStreamResponse_Content() {}

func (*speechToTextStreamResponse_GenerationMetrics) isSpeechToTextStreamResponse_Content() {}

// Holds transcript events.
type SpeechToTextStreamTurnEvent struct {
	state                          protoimpl.MessageState `protogen:"opaque.v1"`
	xxx_hidden_TurnIndex           int32                  `protobuf:"varint,1,opt,name=turn_index,json=turnIndex,proto3"`
	xxx_hidden_Transcript          string                 `protobuf:"bytes,2,opt,name=transcript,proto3"`
	xxx_hidden_EndOfTurnConfidence float64                `protobuf:"fixed64,3,opt,name=end_of_turn_confidence,json=endOfTurnConfidence,proto3"`
	unknownFields                  protoimpl.UnknownFields
	sizeCache                      protoimpl.SizeCache
}

func (x *SpeechToTextStreamTurnEvent) Reset() {
	*x = SpeechToTextStreamTurnEvent{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextStreamTurnEvent) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextStreamTurnEvent) ProtoMessage() {}

func (x *SpeechToTextStreamTurnEvent) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextStreamTurnEvent) GetTurnIndex() int32 {
	if x != nil {
		return x.xxx_hidden_TurnIndex
	}
	return 0
}

func (x *SpeechToTextStreamTurnEvent) GetTranscript() string {
	if x != nil {
		return x.xxx_hidden_Transcript
	}
	return ""
}

func (x *SpeechToTextStreamTurnEvent) GetEndOfTurnConfidence() float64 {
	if x != nil {
		return x.xxx_hidden_EndOfTurnConfidence
	}
	return 0
}

func (x *SpeechToTextStreamTurnEvent) SetTurnIndex(v int32) {
	x.xxx_hidden_TurnIndex = v
}

func (x *SpeechToTextStreamTurnEvent) SetTranscript(v string) {
	x.xxx_hidden_Transcript = v
}

func (x *SpeechToTextStreamTurnEvent) SetEndOfTurnConfidence(v float64) {
	x.xxx_hidden_EndOfTurnConfidence = v
}

type SpeechToTextStreamTurnEvent_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// Index of the turn this event belongs to, starts at zero.
	TurnIndex int32
	// Transcript for this turn so far.
	Transcript string
	// Confidence score (0.0 to 1.0) that this turn has ended.
	EndOfTurnConfidence float64
}

func (b0 SpeechToTextStreamTurnEvent_builder) Build() *SpeechToTextStreamTurnEvent {
	m0 := &SpeechToTextStreamTurnEvent{}
	b, x := &b0, m0
	_, _ = b, x
	x.xxx_hidden_TurnIndex = b.TurnIndex
	x.xxx_hidden_Transcript = b.Transcript
	x.xxx_hidden_EndOfTurnConfidence = b.EndOfTurnConfidence
	return m0
}

var File_malonaz_ai_ai_service_v1_speech_to_text_proto protoreflect.FileDescriptor

const file_malonaz_ai_ai_service_v1_speech_to_text_proto_rawDesc = "" +
	"\n" +
	"-malonaz/ai/ai_service/v1/speech_to_text.proto\x12\x18malonaz.ai.ai_service.v1\x1a\x1bbuf/validate/validate.proto\x1a\x19google/api/resource.proto\x1a\x1egoogle/protobuf/duration.proto\x1a\x1bmalonaz/ai/v1/metrics.proto\x1a\x1cmalonaz/audio/v1/audio.proto\"\xf8\x01\n" +
	"\x13SpeechToTextRequest\x125\n" +
	"\x05model\x18\x01 \x01(\tB\x1f\xfaA\x16\n" +
	"\x14ai.malonaz.com/Model\xbaH\x03\xc8\x01\x01R\x05model\x12C\n" +
	"\faudio_format\x18\x02 \x01(\v2\x18.malonaz.audio.v1.FormatB\x06\xbaH\x03\xc8\x01\x01R\vaudioFormat\x12@\n" +
	"\vaudio_chunk\x18\x03 \x01(\v2\x17.malonaz.audio.v1.ChunkB\x06\xbaH\x03\xc8\x01\x01R\n" +
	"audioChunk\x12#\n" +
	"\rlanguage_code\x18\x04 \x01(\tR\flanguageCode\"\xc3\x01\n" +
	"\x14SpeechToTextResponse\x12\x1e\n" +
	"\n" +
	"transcript\x18\x01 \x01(\tR\n" +
	"transcript\x12:\n" +
	"\vmodel_usage\x18\x02 \x01(\v2\x19.malonaz.ai.v1.ModelUsageR\n" +
	"modelUsage\x12O\n" +
	"\x12generation_metrics\x18\x03 \x01(\v2 .malonaz.ai.v1.GenerationMetricsR\x11generationMetrics\"\xcc\x01\n" +
	"\x19SpeechToTextStreamRequest\x12a\n" +
	"\rconfiguration\x18\x01 \x01(\v29.malonaz.ai.ai_service.v1.SpeechToTextStreamConfigurationH\x00R\rconfiguration\x12:\n" +
	"\vaudio_chunk\x18\x02 \x01(\v2\x17.malonaz.audio.v1.ChunkH\x00R\n" +
	"audioChunkB\x10\n" +
	"\acontent\x12\x05\xbaH\x02\b\x01\"\xaa\x05\n" +
	"\x1fSpeechToTextStreamConfiguration\x125\n" +
	"\x05model\x18\x01 \x01(\tB\x1f\xfaA\x16\n" +
	"\x14ai.malonaz.com/Model\xbaH\x03\xc8\x01\x01R\x05model\x12C\n" +
	"\faudio_format\x18\x02 \x01(\v2\x18.malonaz.audio.v1.FormatB\x06\xbaH\x03\xc8\x01\x01R\vaudioFormat\x12_\n" +
	" end_of_turn_confidence_threshold\x18\x03 \x01(\x01B\x17\xbaH\x14\x12\x12\x19\x00\x00\x00\x00\x00\x00\xf0?)\x00\x00\x00\x00\x00\x00\x00\x00R\x1cendOfTurnConfidenceThreshold\x12j\n" +
	"&eager_end_of_turn_confidence_threshold\x18\x04 \x01(\x01B\x17\xbaH\x14\x12\x12\x19\x00\x00\x00\x00\x00\x00\xf0?)\x00\x00\x00\x00\x00\x00\x00\x00R!eagerEndOfTurnConfidenceThreshold\x12V\n" +
	"\x13end_of_turn_timeout\x18\x05 \x01(\v2\x19.google.protobuf.DurationB\f\xbaH\t\xaa\x01\x06\"\x02\b\n" +
	"2\x00R\x10endOfTurnTimeout\x12#\n" +
	"\rlanguage_code\x18\x06 \x01(\tR\flanguageCode:\xc0\x01\xbaH\xbc\x01\x1a\xb9\x01\n" +
	"\reager_lte_eot\x12Reager_end_of_turn_confidence_threshold must be <= end_of_turn_confidence_threshold\x1aTthis.eager_end_of_turn_confidence_threshold <= this.end_of_turn_confidence_threshold\"\x80\x05\n" +
	"\x1aSpeechToTextStreamResponse\x12V\n" +
	"\n" +
	"turn_start\x18\x01 \x01(\v25.malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEventH\x00R\tturnStart\x12X\n" +
	"\vturn_update\x18\x02 \x01(\v25.malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEventH\x00R\n" +
	"turnUpdate\x12]\n" +
	"\x0eturn_eager_end\x18\x03 \x01(\v25.malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEventH\x00R\fturnEagerEnd\x12Z\n" +
	"\fturn_resumed\x18\x04 \x01(\v25.malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEventH\x00R\vturnResumed\x12R\n" +
	"\bturn_end\x18\x05 \x01(\v25.malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEventH\x00R\aturnEnd\x12<\n" +
	"\vmodel_usage\x18\x06 \x01(\v2\x19.malonaz.ai.v1.ModelUsageH\x00R\n" +
	"modelUsage\x12Q\n" +
	"\x12generation_metrics\x18\a \x01(\v2 .malonaz.ai.v1.GenerationMetricsH\x00R\x11generationMetricsB\x10\n" +
	"\acontent\x12\x05\xbaH\x02\b\x01\"\x91\x01\n" +
	"\x1bSpeechToTextStreamTurnEvent\x12\x1d\n" +
	"\n" +
	"turn_index\x18\x01 \x01(\x05R\tturnIndex\x12\x1e\n" +
	"\n" +
	"transcript\x18\x02 \x01(\tR\n" +
	"transcript\x123\n" +
	"\x16end_of_turn_confidence\x18\x03 \x01(\x01R\x13endOfTurnConfidenceB3Z1github.com/malonaz/core/genproto/ai/ai_service/v1b\x06proto3"

var file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes = make([]protoimpl.MessageInfo, 6)
var file_malonaz_ai_ai_service_v1_speech_to_text_proto_goTypes = []any{
	(*SpeechToTextRequest)(nil),             // 0: malonaz.ai.ai_service.v1.SpeechToTextRequest
	(*SpeechToTextResponse)(nil),            // 1: malonaz.ai.ai_service.v1.SpeechToTextResponse
	(*SpeechToTextStreamRequest)(nil),       // 2: malonaz.ai.ai_service.v1.SpeechToTextStreamRequest
	(*SpeechToTextStreamConfiguration)(nil), // 3: malonaz.ai.ai_service.v1.SpeechToTextStreamConfiguration
	(*SpeechToTextStreamResponse)(nil),      // 4: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse
	(*SpeechToTextStreamTurnEvent)(nil),     // 5: malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	(*v1.Format)(nil),                       // 6: malonaz.audio.v1.Format
	(*v1.Chunk)(nil),                        // 7: malonaz.audio.v1.Chunk
	(*v11.ModelUsage)(nil),                  // 8: malonaz.ai.v1.ModelUsage
	(*v11.GenerationMetrics)(nil),           // 9: malonaz.ai.v1.GenerationMetrics
	(*durationpb.Duration)(nil),             // 10: google.protobuf.Duration
}
var file_malonaz_ai_ai_service_v1_speech_to_text_proto_depIdxs = []int32{
	6,  // 0: malonaz.ai.ai_service.v1.SpeechToTextRequest.audio_format:type_name -> malonaz.audio.v1.Format
	7,  // 1: malonaz.ai.ai_service.v1.SpeechToTextRequest.audio_chunk:type_name -> malonaz.audio.v1.Chunk
	8,  // 2: malonaz.ai.ai_service.v1.SpeechToTextResponse.model_usage:type_name -> malonaz.ai.v1.ModelUsage
	9,  // 3: malonaz.ai.ai_service.v1.SpeechToTextResponse.generation_metrics:type_name -> malonaz.ai.v1.GenerationMetrics
	3,  // 4: malonaz.ai.ai_service.v1.SpeechToTextStreamRequest.configuration:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamConfiguration
	7,  // 5: malonaz.ai.ai_service.v1.SpeechToTextStreamRequest.audio_chunk:type_name -> malonaz.audio.v1.Chunk
	6,  // 6: malonaz.ai.ai_service.v1.SpeechToTextStreamConfiguration.audio_format:type_name -> malonaz.audio.v1.Format
	10, // 7: malonaz.ai.ai_service.v1.SpeechToTextStreamConfiguration.end_of_turn_timeout:type_name -> google.protobuf.Duration
	5,  // 8: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.turn_start:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	5,  // 9: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.turn_update:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	5,  // 10: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.turn_eager_end:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	5,  // 11: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.turn_resumed:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	5,  // 12: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.turn_end:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	8,  // 13: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.model_usage:type_name -> malonaz.ai.v1.ModelUsage
	9,  // 14: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.generation_metrics:type_name -> malonaz.ai.v1.GenerationMetrics
	15, // [15:15] is the sub-list for method output_type
	15, // [15:15] is the sub-list for method input_type
	15, // [15:15] is the sub-list for extension type_name
	15, // [15:15] is the sub-list for extension extendee
	0,  // [0:15] is the sub-list for field type_name
}

func init() { file_malonaz_ai_ai_service_v1_speech_to_text_proto_init() }
func file_malonaz_ai_ai_service_v1_speech_to_text_proto_init() {
	if File_malonaz_ai_ai_service_v1_speech_to_text_proto != nil {
		return
	}
	file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[2].OneofWrappers = []any{
		(*speechToTextStreamRequest_Configuration)(nil),
		(*speechToTextStreamRequest_AudioChunk)(nil),
	}
	file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[4].OneofWrappers = []any{
		(*speechToTextStreamResponse_TurnStart)(nil),
		(*speechToTextStreamResponse_TurnUpdate)(nil),
		(*speechToTextStreamResponse_TurnEagerEnd)(nil),
		(*speechToTextStreamResponse_TurnResumed)(nil),
		(*speechToTextStreamResponse_TurnEnd)(nil),
		(*speechToTextStreamResponse_ModelUsage)(nil),
		(*speechToTextStreamResponse_GenerationMetrics)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_malonaz_ai_ai_service_v1_speech_to_text_proto_rawDesc), len(file_malonaz_ai_ai_service_v1_speech_to_text_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   6,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_malonaz_ai_ai_service_v1_speech_to_text_proto_goTypes,
		DependencyIndexes: file_malonaz_ai_ai_service_v1_speech_to_text_proto_depIdxs,
		MessageInfos:      file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes,
	}.Build()
	File_malonaz_ai_ai_service_v1_speech_to_text_proto = out.File
	file_malonaz_ai_ai_service_v1_speech_to_text_proto_goTypes = nil
	file_malonaz_ai_ai_service_v1_speech_to_text_proto_depIdxs = nil
}
