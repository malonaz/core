// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v6.32.1
// source: malonaz/ai/ai_service/v1/speech_to_text.proto

//go:build !protoopaque

package v1

import (
	_ "buf.build/gen/go/bufbuild/protovalidate/protocolbuffers/go/buf/validate"
	v11 "github.com/malonaz/core/genproto/ai/v1"
	v1 "github.com/malonaz/core/genproto/audio/v1"
	_ "google.golang.org/genproto/googleapis/api/annotations"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	durationpb "google.golang.org/protobuf/types/known/durationpb"
	reflect "reflect"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Request message for AiService.SpeechToText.
type SpeechToTextRequest struct {
	state protoimpl.MessageState `protogen:"hybrid.v1"`
	// The resource name of the model used.
	// Format: providers/{provider}/models/{model}
	Model string `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	// Audio format of the audio.
	AudioFormat *v1.Format `protobuf:"bytes,2,opt,name=audio_format,json=audioFormat,proto3" json:"audio_format,omitempty"`
	// Audio to transcribe.
	AudioChunk *v1.Chunk `protobuf:"bytes,3,opt,name=audio_chunk,json=audioChunk,proto3" json:"audio_chunk,omitempty"`
	// Optional language code to improve transcription accuracy (e.g., "en", "es").
	LanguageCode  string `protobuf:"bytes,4,opt,name=language_code,json=languageCode,proto3" json:"language_code,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SpeechToTextRequest) Reset() {
	*x = SpeechToTextRequest{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextRequest) ProtoMessage() {}

func (x *SpeechToTextRequest) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *SpeechToTextRequest) GetAudioFormat() *v1.Format {
	if x != nil {
		return x.AudioFormat
	}
	return nil
}

func (x *SpeechToTextRequest) GetAudioChunk() *v1.Chunk {
	if x != nil {
		return x.AudioChunk
	}
	return nil
}

func (x *SpeechToTextRequest) GetLanguageCode() string {
	if x != nil {
		return x.LanguageCode
	}
	return ""
}

func (x *SpeechToTextRequest) SetModel(v string) {
	x.Model = v
}

func (x *SpeechToTextRequest) SetAudioFormat(v *v1.Format) {
	x.AudioFormat = v
}

func (x *SpeechToTextRequest) SetAudioChunk(v *v1.Chunk) {
	x.AudioChunk = v
}

func (x *SpeechToTextRequest) SetLanguageCode(v string) {
	x.LanguageCode = v
}

func (x *SpeechToTextRequest) HasAudioFormat() bool {
	if x == nil {
		return false
	}
	return x.AudioFormat != nil
}

func (x *SpeechToTextRequest) HasAudioChunk() bool {
	if x == nil {
		return false
	}
	return x.AudioChunk != nil
}

func (x *SpeechToTextRequest) ClearAudioFormat() {
	x.AudioFormat = nil
}

func (x *SpeechToTextRequest) ClearAudioChunk() {
	x.AudioChunk = nil
}

type SpeechToTextRequest_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The resource name of the model used.
	// Format: providers/{provider}/models/{model}
	Model string
	// Audio format of the audio.
	AudioFormat *v1.Format
	// Audio to transcribe.
	AudioChunk *v1.Chunk
	// Optional language code to improve transcription accuracy (e.g., "en", "es").
	LanguageCode string
}

func (b0 SpeechToTextRequest_builder) Build() *SpeechToTextRequest {
	m0 := &SpeechToTextRequest{}
	b, x := &b0, m0
	_, _ = b, x
	x.Model = b.Model
	x.AudioFormat = b.AudioFormat
	x.AudioChunk = b.AudioChunk
	x.LanguageCode = b.LanguageCode
	return m0
}

// Response message for AiService.SpeechToText.
type SpeechToTextResponse struct {
	state protoimpl.MessageState `protogen:"hybrid.v1"`
	// The transcribed text.
	Transcript string `protobuf:"bytes,1,opt,name=transcript,proto3" json:"transcript,omitempty"`
	// Model usage metrics.
	ModelUsage *v11.ModelUsage `protobuf:"bytes,2,opt,name=model_usage,json=modelUsage,proto3" json:"model_usage,omitempty"`
	// Generation metrics.
	GenerationMetrics *v11.GenerationMetrics `protobuf:"bytes,3,opt,name=generation_metrics,json=generationMetrics,proto3" json:"generation_metrics,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *SpeechToTextResponse) Reset() {
	*x = SpeechToTextResponse{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextResponse) ProtoMessage() {}

func (x *SpeechToTextResponse) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextResponse) GetTranscript() string {
	if x != nil {
		return x.Transcript
	}
	return ""
}

func (x *SpeechToTextResponse) GetModelUsage() *v11.ModelUsage {
	if x != nil {
		return x.ModelUsage
	}
	return nil
}

func (x *SpeechToTextResponse) GetGenerationMetrics() *v11.GenerationMetrics {
	if x != nil {
		return x.GenerationMetrics
	}
	return nil
}

func (x *SpeechToTextResponse) SetTranscript(v string) {
	x.Transcript = v
}

func (x *SpeechToTextResponse) SetModelUsage(v *v11.ModelUsage) {
	x.ModelUsage = v
}

func (x *SpeechToTextResponse) SetGenerationMetrics(v *v11.GenerationMetrics) {
	x.GenerationMetrics = v
}

func (x *SpeechToTextResponse) HasModelUsage() bool {
	if x == nil {
		return false
	}
	return x.ModelUsage != nil
}

func (x *SpeechToTextResponse) HasGenerationMetrics() bool {
	if x == nil {
		return false
	}
	return x.GenerationMetrics != nil
}

func (x *SpeechToTextResponse) ClearModelUsage() {
	x.ModelUsage = nil
}

func (x *SpeechToTextResponse) ClearGenerationMetrics() {
	x.GenerationMetrics = nil
}

type SpeechToTextResponse_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The transcribed text.
	Transcript string
	// Model usage metrics.
	ModelUsage *v11.ModelUsage
	// Generation metrics.
	GenerationMetrics *v11.GenerationMetrics
}

func (b0 SpeechToTextResponse_builder) Build() *SpeechToTextResponse {
	m0 := &SpeechToTextResponse{}
	b, x := &b0, m0
	_, _ = b, x
	x.Transcript = b.Transcript
	x.ModelUsage = b.ModelUsage
	x.GenerationMetrics = b.GenerationMetrics
	return m0
}

// Request message for AiService.SpeechToTextStream.
type SpeechToTextStreamRequest struct {
	state protoimpl.MessageState `protogen:"hybrid.v1"`
	// Content of this request.
	//
	// Types that are valid to be assigned to Content:
	//
	//	*SpeechToTextStreamRequest_Configuration
	//	*SpeechToTextStreamRequest_AudioChunk
	Content       isSpeechToTextStreamRequest_Content `protobuf_oneof:"content"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SpeechToTextStreamRequest) Reset() {
	*x = SpeechToTextStreamRequest{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextStreamRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextStreamRequest) ProtoMessage() {}

func (x *SpeechToTextStreamRequest) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextStreamRequest) GetContent() isSpeechToTextStreamRequest_Content {
	if x != nil {
		return x.Content
	}
	return nil
}

func (x *SpeechToTextStreamRequest) GetConfiguration() *SpeechToTextStreamConfiguration {
	if x != nil {
		if x, ok := x.Content.(*SpeechToTextStreamRequest_Configuration); ok {
			return x.Configuration
		}
	}
	return nil
}

func (x *SpeechToTextStreamRequest) GetAudioChunk() *v1.Chunk {
	if x != nil {
		if x, ok := x.Content.(*SpeechToTextStreamRequest_AudioChunk); ok {
			return x.AudioChunk
		}
	}
	return nil
}

func (x *SpeechToTextStreamRequest) SetConfiguration(v *SpeechToTextStreamConfiguration) {
	if v == nil {
		x.Content = nil
		return
	}
	x.Content = &SpeechToTextStreamRequest_Configuration{v}
}

func (x *SpeechToTextStreamRequest) SetAudioChunk(v *v1.Chunk) {
	if v == nil {
		x.Content = nil
		return
	}
	x.Content = &SpeechToTextStreamRequest_AudioChunk{v}
}

func (x *SpeechToTextStreamRequest) HasContent() bool {
	if x == nil {
		return false
	}
	return x.Content != nil
}

func (x *SpeechToTextStreamRequest) HasConfiguration() bool {
	if x == nil {
		return false
	}
	_, ok := x.Content.(*SpeechToTextStreamRequest_Configuration)
	return ok
}

func (x *SpeechToTextStreamRequest) HasAudioChunk() bool {
	if x == nil {
		return false
	}
	_, ok := x.Content.(*SpeechToTextStreamRequest_AudioChunk)
	return ok
}

func (x *SpeechToTextStreamRequest) ClearContent() {
	x.Content = nil
}

func (x *SpeechToTextStreamRequest) ClearConfiguration() {
	if _, ok := x.Content.(*SpeechToTextStreamRequest_Configuration); ok {
		x.Content = nil
	}
}

func (x *SpeechToTextStreamRequest) ClearAudioChunk() {
	if _, ok := x.Content.(*SpeechToTextStreamRequest_AudioChunk); ok {
		x.Content = nil
	}
}

const SpeechToTextStreamRequest_Content_not_set_case case_SpeechToTextStreamRequest_Content = 0
const SpeechToTextStreamRequest_Configuration_case case_SpeechToTextStreamRequest_Content = 1
const SpeechToTextStreamRequest_AudioChunk_case case_SpeechToTextStreamRequest_Content = 2

func (x *SpeechToTextStreamRequest) WhichContent() case_SpeechToTextStreamRequest_Content {
	if x == nil {
		return SpeechToTextStreamRequest_Content_not_set_case
	}
	switch x.Content.(type) {
	case *SpeechToTextStreamRequest_Configuration:
		return SpeechToTextStreamRequest_Configuration_case
	case *SpeechToTextStreamRequest_AudioChunk:
		return SpeechToTextStreamRequest_AudioChunk_case
	default:
		return SpeechToTextStreamRequest_Content_not_set_case
	}
}

type SpeechToTextStreamRequest_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// Content of this request.

	// Fields of oneof Content:
	// Configuration for the stream. Must be sent first.
	Configuration *SpeechToTextStreamConfiguration
	// Audio data chunk.
	AudioChunk *v1.Chunk
	// -- end of Content
}

func (b0 SpeechToTextStreamRequest_builder) Build() *SpeechToTextStreamRequest {
	m0 := &SpeechToTextStreamRequest{}
	b, x := &b0, m0
	_, _ = b, x
	if b.Configuration != nil {
		x.Content = &SpeechToTextStreamRequest_Configuration{b.Configuration}
	}
	if b.AudioChunk != nil {
		x.Content = &SpeechToTextStreamRequest_AudioChunk{b.AudioChunk}
	}
	return m0
}

type case_SpeechToTextStreamRequest_Content protoreflect.FieldNumber

func (x case_SpeechToTextStreamRequest_Content) String() string {
	md := file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[2].Descriptor()
	if x == 0 {
		return "not set"
	}
	return protoimpl.X.MessageFieldStringOf(md, protoreflect.FieldNumber(x))
}

type isSpeechToTextStreamRequest_Content interface {
	isSpeechToTextStreamRequest_Content()
}

type SpeechToTextStreamRequest_Configuration struct {
	// Configuration for the stream. Must be sent first.
	Configuration *SpeechToTextStreamConfiguration `protobuf:"bytes,1,opt,name=configuration,proto3,oneof"`
}

type SpeechToTextStreamRequest_AudioChunk struct {
	// Audio data chunk.
	AudioChunk *v1.Chunk `protobuf:"bytes,2,opt,name=audio_chunk,json=audioChunk,proto3,oneof"`
}

func (*SpeechToTextStreamRequest_Configuration) isSpeechToTextStreamRequest_Content() {}

func (*SpeechToTextStreamRequest_AudioChunk) isSpeechToTextStreamRequest_Content() {}

// Configuration for speech to text streaming. Sent as the first message.
type SpeechToTextStreamConfiguration struct {
	state protoimpl.MessageState `protogen:"hybrid.v1"`
	// The resource name of the model used.
	// Format: providers/{provider}/models/{model}
	Model string `protobuf:"bytes,1,opt,name=model,proto3" json:"model,omitempty"`
	// Audio format of the audio stream.
	AudioFormat *v1.Format `protobuf:"bytes,2,opt,name=audio_format,json=audioFormat,proto3" json:"audio_format,omitempty"`
	// Optional language code to improve transcription accuracy (e.g., "en", "es").
	LanguageCode string `protobuf:"bytes,3,opt,name=language_code,json=languageCode,proto3" json:"language_code,omitempty"`
	// Strategy for committing transcript segments.
	//
	// Types that are valid to be assigned to CommitStrategy:
	//
	//	*SpeechToTextStreamConfiguration_EndOfTurn
	//	*SpeechToTextStreamConfiguration_Vad
	CommitStrategy isSpeechToTextStreamConfiguration_CommitStrategy `protobuf_oneof:"commit_strategy"`
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *SpeechToTextStreamConfiguration) Reset() {
	*x = SpeechToTextStreamConfiguration{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextStreamConfiguration) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextStreamConfiguration) ProtoMessage() {}

func (x *SpeechToTextStreamConfiguration) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextStreamConfiguration) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *SpeechToTextStreamConfiguration) GetAudioFormat() *v1.Format {
	if x != nil {
		return x.AudioFormat
	}
	return nil
}

func (x *SpeechToTextStreamConfiguration) GetLanguageCode() string {
	if x != nil {
		return x.LanguageCode
	}
	return ""
}

func (x *SpeechToTextStreamConfiguration) GetCommitStrategy() isSpeechToTextStreamConfiguration_CommitStrategy {
	if x != nil {
		return x.CommitStrategy
	}
	return nil
}

func (x *SpeechToTextStreamConfiguration) GetEndOfTurn() *SpeechToTextStreamCommitStrategyEndOfTurn {
	if x != nil {
		if x, ok := x.CommitStrategy.(*SpeechToTextStreamConfiguration_EndOfTurn); ok {
			return x.EndOfTurn
		}
	}
	return nil
}

func (x *SpeechToTextStreamConfiguration) GetVad() *SpeechToTextStreamCommitStrategyVad {
	if x != nil {
		if x, ok := x.CommitStrategy.(*SpeechToTextStreamConfiguration_Vad); ok {
			return x.Vad
		}
	}
	return nil
}

func (x *SpeechToTextStreamConfiguration) SetModel(v string) {
	x.Model = v
}

func (x *SpeechToTextStreamConfiguration) SetAudioFormat(v *v1.Format) {
	x.AudioFormat = v
}

func (x *SpeechToTextStreamConfiguration) SetLanguageCode(v string) {
	x.LanguageCode = v
}

func (x *SpeechToTextStreamConfiguration) SetEndOfTurn(v *SpeechToTextStreamCommitStrategyEndOfTurn) {
	if v == nil {
		x.CommitStrategy = nil
		return
	}
	x.CommitStrategy = &SpeechToTextStreamConfiguration_EndOfTurn{v}
}

func (x *SpeechToTextStreamConfiguration) SetVad(v *SpeechToTextStreamCommitStrategyVad) {
	if v == nil {
		x.CommitStrategy = nil
		return
	}
	x.CommitStrategy = &SpeechToTextStreamConfiguration_Vad{v}
}

func (x *SpeechToTextStreamConfiguration) HasAudioFormat() bool {
	if x == nil {
		return false
	}
	return x.AudioFormat != nil
}

func (x *SpeechToTextStreamConfiguration) HasCommitStrategy() bool {
	if x == nil {
		return false
	}
	return x.CommitStrategy != nil
}

func (x *SpeechToTextStreamConfiguration) HasEndOfTurn() bool {
	if x == nil {
		return false
	}
	_, ok := x.CommitStrategy.(*SpeechToTextStreamConfiguration_EndOfTurn)
	return ok
}

func (x *SpeechToTextStreamConfiguration) HasVad() bool {
	if x == nil {
		return false
	}
	_, ok := x.CommitStrategy.(*SpeechToTextStreamConfiguration_Vad)
	return ok
}

func (x *SpeechToTextStreamConfiguration) ClearAudioFormat() {
	x.AudioFormat = nil
}

func (x *SpeechToTextStreamConfiguration) ClearCommitStrategy() {
	x.CommitStrategy = nil
}

func (x *SpeechToTextStreamConfiguration) ClearEndOfTurn() {
	if _, ok := x.CommitStrategy.(*SpeechToTextStreamConfiguration_EndOfTurn); ok {
		x.CommitStrategy = nil
	}
}

func (x *SpeechToTextStreamConfiguration) ClearVad() {
	if _, ok := x.CommitStrategy.(*SpeechToTextStreamConfiguration_Vad); ok {
		x.CommitStrategy = nil
	}
}

const SpeechToTextStreamConfiguration_CommitStrategy_not_set_case case_SpeechToTextStreamConfiguration_CommitStrategy = 0
const SpeechToTextStreamConfiguration_EndOfTurn_case case_SpeechToTextStreamConfiguration_CommitStrategy = 4
const SpeechToTextStreamConfiguration_Vad_case case_SpeechToTextStreamConfiguration_CommitStrategy = 5

func (x *SpeechToTextStreamConfiguration) WhichCommitStrategy() case_SpeechToTextStreamConfiguration_CommitStrategy {
	if x == nil {
		return SpeechToTextStreamConfiguration_CommitStrategy_not_set_case
	}
	switch x.CommitStrategy.(type) {
	case *SpeechToTextStreamConfiguration_EndOfTurn:
		return SpeechToTextStreamConfiguration_EndOfTurn_case
	case *SpeechToTextStreamConfiguration_Vad:
		return SpeechToTextStreamConfiguration_Vad_case
	default:
		return SpeechToTextStreamConfiguration_CommitStrategy_not_set_case
	}
}

type SpeechToTextStreamConfiguration_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// The resource name of the model used.
	// Format: providers/{provider}/models/{model}
	Model string
	// Audio format of the audio stream.
	AudioFormat *v1.Format
	// Optional language code to improve transcription accuracy (e.g., "en", "es").
	LanguageCode string
	// Strategy for committing transcript segments.

	// Fields of oneof CommitStrategy:
	// End of turn configuration.
	EndOfTurn *SpeechToTextStreamCommitStrategyEndOfTurn
	// Vad configuration.
	Vad *SpeechToTextStreamCommitStrategyVad
	// -- end of CommitStrategy
}

func (b0 SpeechToTextStreamConfiguration_builder) Build() *SpeechToTextStreamConfiguration {
	m0 := &SpeechToTextStreamConfiguration{}
	b, x := &b0, m0
	_, _ = b, x
	x.Model = b.Model
	x.AudioFormat = b.AudioFormat
	x.LanguageCode = b.LanguageCode
	if b.EndOfTurn != nil {
		x.CommitStrategy = &SpeechToTextStreamConfiguration_EndOfTurn{b.EndOfTurn}
	}
	if b.Vad != nil {
		x.CommitStrategy = &SpeechToTextStreamConfiguration_Vad{b.Vad}
	}
	return m0
}

type case_SpeechToTextStreamConfiguration_CommitStrategy protoreflect.FieldNumber

func (x case_SpeechToTextStreamConfiguration_CommitStrategy) String() string {
	md := file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[3].Descriptor()
	if x == 0 {
		return "not set"
	}
	return protoimpl.X.MessageFieldStringOf(md, protoreflect.FieldNumber(x))
}

type isSpeechToTextStreamConfiguration_CommitStrategy interface {
	isSpeechToTextStreamConfiguration_CommitStrategy()
}

type SpeechToTextStreamConfiguration_EndOfTurn struct {
	// End of turn configuration.
	EndOfTurn *SpeechToTextStreamCommitStrategyEndOfTurn `protobuf:"bytes,4,opt,name=end_of_turn,json=endOfTurn,proto3,oneof"`
}

type SpeechToTextStreamConfiguration_Vad struct {
	// Vad configuration.
	Vad *SpeechToTextStreamCommitStrategyVad `protobuf:"bytes,5,opt,name=vad,proto3,oneof"`
}

func (*SpeechToTextStreamConfiguration_EndOfTurn) isSpeechToTextStreamConfiguration_CommitStrategy() {
}

func (*SpeechToTextStreamConfiguration_Vad) isSpeechToTextStreamConfiguration_CommitStrategy() {}

// Configuration for end-of-turn detection.
type SpeechToTextStreamCommitStrategyEndOfTurn struct {
	state protoimpl.MessageState `protogen:"hybrid.v1"`
	// Confidence threshold for ending a turn.
	ConfidenceThreshold float64 `protobuf:"fixed64,1,opt,name=confidence_threshold,json=confidenceThreshold,proto3" json:"confidence_threshold,omitempty"`
	// Eager confidence threshold (must be <= confidence_threshold).
	EagerConfidenceThreshold float64 `protobuf:"fixed64,2,opt,name=eager_confidence_threshold,json=eagerConfidenceThreshold,proto3" json:"eager_confidence_threshold,omitempty"`
	// Maximum silence duration before forcing end of turn after speech starts.
	Timeout       *durationpb.Duration `protobuf:"bytes,3,opt,name=timeout,proto3" json:"timeout,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) Reset() {
	*x = SpeechToTextStreamCommitStrategyEndOfTurn{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextStreamCommitStrategyEndOfTurn) ProtoMessage() {}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) GetConfidenceThreshold() float64 {
	if x != nil {
		return x.ConfidenceThreshold
	}
	return 0
}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) GetEagerConfidenceThreshold() float64 {
	if x != nil {
		return x.EagerConfidenceThreshold
	}
	return 0
}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) GetTimeout() *durationpb.Duration {
	if x != nil {
		return x.Timeout
	}
	return nil
}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) SetConfidenceThreshold(v float64) {
	x.ConfidenceThreshold = v
}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) SetEagerConfidenceThreshold(v float64) {
	x.EagerConfidenceThreshold = v
}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) SetTimeout(v *durationpb.Duration) {
	x.Timeout = v
}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) HasTimeout() bool {
	if x == nil {
		return false
	}
	return x.Timeout != nil
}

func (x *SpeechToTextStreamCommitStrategyEndOfTurn) ClearTimeout() {
	x.Timeout = nil
}

type SpeechToTextStreamCommitStrategyEndOfTurn_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// Confidence threshold for ending a turn.
	ConfidenceThreshold float64
	// Eager confidence threshold (must be <= confidence_threshold).
	EagerConfidenceThreshold float64
	// Maximum silence duration before forcing end of turn after speech starts.
	Timeout *durationpb.Duration
}

func (b0 SpeechToTextStreamCommitStrategyEndOfTurn_builder) Build() *SpeechToTextStreamCommitStrategyEndOfTurn {
	m0 := &SpeechToTextStreamCommitStrategyEndOfTurn{}
	b, x := &b0, m0
	_, _ = b, x
	x.ConfidenceThreshold = b.ConfidenceThreshold
	x.EagerConfidenceThreshold = b.EagerConfidenceThreshold
	x.Timeout = b.Timeout
	return m0
}

// Configuration for vad.
type SpeechToTextStreamCommitStrategyVad struct {
	state protoimpl.MessageState `protogen:"hybrid.v1"`
	// Silence duration before committing transcript. Must be between 0.3s and 3.0s.
	SilenceThreshold *durationpb.Duration `protobuf:"bytes,1,opt,name=silence_threshold,json=silenceThreshold,proto3" json:"silence_threshold,omitempty"`
	// Voice activity detection sensitivity. Must be between 0.1 and 0.9.
	VadThreshold float64 `protobuf:"fixed64,2,opt,name=vad_threshold,json=vadThreshold,proto3" json:"vad_threshold,omitempty"`
	// Minimum speech duration to consider valid. Must be between 50ms and 2000ms.
	MinSpeechDuration *durationpb.Duration `protobuf:"bytes,3,opt,name=min_speech_duration,json=minSpeechDuration,proto3" json:"min_speech_duration,omitempty"`
	// Minimum silence duration before speech is considered ended. Must be between 50ms and 2000ms.
	MinSilenceDuration *durationpb.Duration `protobuf:"bytes,4,opt,name=min_silence_duration,json=minSilenceDuration,proto3" json:"min_silence_duration,omitempty"`
	unknownFields      protoimpl.UnknownFields
	sizeCache          protoimpl.SizeCache
}

func (x *SpeechToTextStreamCommitStrategyVad) Reset() {
	*x = SpeechToTextStreamCommitStrategyVad{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextStreamCommitStrategyVad) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextStreamCommitStrategyVad) ProtoMessage() {}

func (x *SpeechToTextStreamCommitStrategyVad) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextStreamCommitStrategyVad) GetSilenceThreshold() *durationpb.Duration {
	if x != nil {
		return x.SilenceThreshold
	}
	return nil
}

func (x *SpeechToTextStreamCommitStrategyVad) GetVadThreshold() float64 {
	if x != nil {
		return x.VadThreshold
	}
	return 0
}

func (x *SpeechToTextStreamCommitStrategyVad) GetMinSpeechDuration() *durationpb.Duration {
	if x != nil {
		return x.MinSpeechDuration
	}
	return nil
}

func (x *SpeechToTextStreamCommitStrategyVad) GetMinSilenceDuration() *durationpb.Duration {
	if x != nil {
		return x.MinSilenceDuration
	}
	return nil
}

func (x *SpeechToTextStreamCommitStrategyVad) SetSilenceThreshold(v *durationpb.Duration) {
	x.SilenceThreshold = v
}

func (x *SpeechToTextStreamCommitStrategyVad) SetVadThreshold(v float64) {
	x.VadThreshold = v
}

func (x *SpeechToTextStreamCommitStrategyVad) SetMinSpeechDuration(v *durationpb.Duration) {
	x.MinSpeechDuration = v
}

func (x *SpeechToTextStreamCommitStrategyVad) SetMinSilenceDuration(v *durationpb.Duration) {
	x.MinSilenceDuration = v
}

func (x *SpeechToTextStreamCommitStrategyVad) HasSilenceThreshold() bool {
	if x == nil {
		return false
	}
	return x.SilenceThreshold != nil
}

func (x *SpeechToTextStreamCommitStrategyVad) HasMinSpeechDuration() bool {
	if x == nil {
		return false
	}
	return x.MinSpeechDuration != nil
}

func (x *SpeechToTextStreamCommitStrategyVad) HasMinSilenceDuration() bool {
	if x == nil {
		return false
	}
	return x.MinSilenceDuration != nil
}

func (x *SpeechToTextStreamCommitStrategyVad) ClearSilenceThreshold() {
	x.SilenceThreshold = nil
}

func (x *SpeechToTextStreamCommitStrategyVad) ClearMinSpeechDuration() {
	x.MinSpeechDuration = nil
}

func (x *SpeechToTextStreamCommitStrategyVad) ClearMinSilenceDuration() {
	x.MinSilenceDuration = nil
}

type SpeechToTextStreamCommitStrategyVad_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// Silence duration before committing transcript. Must be between 0.3s and 3.0s.
	SilenceThreshold *durationpb.Duration
	// Voice activity detection sensitivity. Must be between 0.1 and 0.9.
	VadThreshold float64
	// Minimum speech duration to consider valid. Must be between 50ms and 2000ms.
	MinSpeechDuration *durationpb.Duration
	// Minimum silence duration before speech is considered ended. Must be between 50ms and 2000ms.
	MinSilenceDuration *durationpb.Duration
}

func (b0 SpeechToTextStreamCommitStrategyVad_builder) Build() *SpeechToTextStreamCommitStrategyVad {
	m0 := &SpeechToTextStreamCommitStrategyVad{}
	b, x := &b0, m0
	_, _ = b, x
	x.SilenceThreshold = b.SilenceThreshold
	x.VadThreshold = b.VadThreshold
	x.MinSpeechDuration = b.MinSpeechDuration
	x.MinSilenceDuration = b.MinSilenceDuration
	return m0
}

// Response message for AiService.SpeechToTextStream.
type SpeechToTextStreamResponse struct {
	state protoimpl.MessageState `protogen:"hybrid.v1"`
	// Content of this response.
	//
	// Types that are valid to be assigned to Content:
	//
	//	*SpeechToTextStreamResponse_TurnStart
	//	*SpeechToTextStreamResponse_TurnUpdate
	//	*SpeechToTextStreamResponse_TurnEagerEnd
	//	*SpeechToTextStreamResponse_TurnResumed
	//	*SpeechToTextStreamResponse_TurnEnd
	//	*SpeechToTextStreamResponse_ModelUsage
	//	*SpeechToTextStreamResponse_GenerationMetrics
	Content       isSpeechToTextStreamResponse_Content `protobuf_oneof:"content"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SpeechToTextStreamResponse) Reset() {
	*x = SpeechToTextStreamResponse{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextStreamResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextStreamResponse) ProtoMessage() {}

func (x *SpeechToTextStreamResponse) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextStreamResponse) GetContent() isSpeechToTextStreamResponse_Content {
	if x != nil {
		return x.Content
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetTurnStart() *SpeechToTextStreamTurnEvent {
	if x != nil {
		if x, ok := x.Content.(*SpeechToTextStreamResponse_TurnStart); ok {
			return x.TurnStart
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetTurnUpdate() *SpeechToTextStreamTurnEvent {
	if x != nil {
		if x, ok := x.Content.(*SpeechToTextStreamResponse_TurnUpdate); ok {
			return x.TurnUpdate
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetTurnEagerEnd() *SpeechToTextStreamTurnEvent {
	if x != nil {
		if x, ok := x.Content.(*SpeechToTextStreamResponse_TurnEagerEnd); ok {
			return x.TurnEagerEnd
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetTurnResumed() *SpeechToTextStreamTurnEvent {
	if x != nil {
		if x, ok := x.Content.(*SpeechToTextStreamResponse_TurnResumed); ok {
			return x.TurnResumed
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetTurnEnd() *SpeechToTextStreamTurnEvent {
	if x != nil {
		if x, ok := x.Content.(*SpeechToTextStreamResponse_TurnEnd); ok {
			return x.TurnEnd
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetModelUsage() *v11.ModelUsage {
	if x != nil {
		if x, ok := x.Content.(*SpeechToTextStreamResponse_ModelUsage); ok {
			return x.ModelUsage
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) GetGenerationMetrics() *v11.GenerationMetrics {
	if x != nil {
		if x, ok := x.Content.(*SpeechToTextStreamResponse_GenerationMetrics); ok {
			return x.GenerationMetrics
		}
	}
	return nil
}

func (x *SpeechToTextStreamResponse) SetTurnStart(v *SpeechToTextStreamTurnEvent) {
	if v == nil {
		x.Content = nil
		return
	}
	x.Content = &SpeechToTextStreamResponse_TurnStart{v}
}

func (x *SpeechToTextStreamResponse) SetTurnUpdate(v *SpeechToTextStreamTurnEvent) {
	if v == nil {
		x.Content = nil
		return
	}
	x.Content = &SpeechToTextStreamResponse_TurnUpdate{v}
}

func (x *SpeechToTextStreamResponse) SetTurnEagerEnd(v *SpeechToTextStreamTurnEvent) {
	if v == nil {
		x.Content = nil
		return
	}
	x.Content = &SpeechToTextStreamResponse_TurnEagerEnd{v}
}

func (x *SpeechToTextStreamResponse) SetTurnResumed(v *SpeechToTextStreamTurnEvent) {
	if v == nil {
		x.Content = nil
		return
	}
	x.Content = &SpeechToTextStreamResponse_TurnResumed{v}
}

func (x *SpeechToTextStreamResponse) SetTurnEnd(v *SpeechToTextStreamTurnEvent) {
	if v == nil {
		x.Content = nil
		return
	}
	x.Content = &SpeechToTextStreamResponse_TurnEnd{v}
}

func (x *SpeechToTextStreamResponse) SetModelUsage(v *v11.ModelUsage) {
	if v == nil {
		x.Content = nil
		return
	}
	x.Content = &SpeechToTextStreamResponse_ModelUsage{v}
}

func (x *SpeechToTextStreamResponse) SetGenerationMetrics(v *v11.GenerationMetrics) {
	if v == nil {
		x.Content = nil
		return
	}
	x.Content = &SpeechToTextStreamResponse_GenerationMetrics{v}
}

func (x *SpeechToTextStreamResponse) HasContent() bool {
	if x == nil {
		return false
	}
	return x.Content != nil
}

func (x *SpeechToTextStreamResponse) HasTurnStart() bool {
	if x == nil {
		return false
	}
	_, ok := x.Content.(*SpeechToTextStreamResponse_TurnStart)
	return ok
}

func (x *SpeechToTextStreamResponse) HasTurnUpdate() bool {
	if x == nil {
		return false
	}
	_, ok := x.Content.(*SpeechToTextStreamResponse_TurnUpdate)
	return ok
}

func (x *SpeechToTextStreamResponse) HasTurnEagerEnd() bool {
	if x == nil {
		return false
	}
	_, ok := x.Content.(*SpeechToTextStreamResponse_TurnEagerEnd)
	return ok
}

func (x *SpeechToTextStreamResponse) HasTurnResumed() bool {
	if x == nil {
		return false
	}
	_, ok := x.Content.(*SpeechToTextStreamResponse_TurnResumed)
	return ok
}

func (x *SpeechToTextStreamResponse) HasTurnEnd() bool {
	if x == nil {
		return false
	}
	_, ok := x.Content.(*SpeechToTextStreamResponse_TurnEnd)
	return ok
}

func (x *SpeechToTextStreamResponse) HasModelUsage() bool {
	if x == nil {
		return false
	}
	_, ok := x.Content.(*SpeechToTextStreamResponse_ModelUsage)
	return ok
}

func (x *SpeechToTextStreamResponse) HasGenerationMetrics() bool {
	if x == nil {
		return false
	}
	_, ok := x.Content.(*SpeechToTextStreamResponse_GenerationMetrics)
	return ok
}

func (x *SpeechToTextStreamResponse) ClearContent() {
	x.Content = nil
}

func (x *SpeechToTextStreamResponse) ClearTurnStart() {
	if _, ok := x.Content.(*SpeechToTextStreamResponse_TurnStart); ok {
		x.Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearTurnUpdate() {
	if _, ok := x.Content.(*SpeechToTextStreamResponse_TurnUpdate); ok {
		x.Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearTurnEagerEnd() {
	if _, ok := x.Content.(*SpeechToTextStreamResponse_TurnEagerEnd); ok {
		x.Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearTurnResumed() {
	if _, ok := x.Content.(*SpeechToTextStreamResponse_TurnResumed); ok {
		x.Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearTurnEnd() {
	if _, ok := x.Content.(*SpeechToTextStreamResponse_TurnEnd); ok {
		x.Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearModelUsage() {
	if _, ok := x.Content.(*SpeechToTextStreamResponse_ModelUsage); ok {
		x.Content = nil
	}
}

func (x *SpeechToTextStreamResponse) ClearGenerationMetrics() {
	if _, ok := x.Content.(*SpeechToTextStreamResponse_GenerationMetrics); ok {
		x.Content = nil
	}
}

const SpeechToTextStreamResponse_Content_not_set_case case_SpeechToTextStreamResponse_Content = 0
const SpeechToTextStreamResponse_TurnStart_case case_SpeechToTextStreamResponse_Content = 1
const SpeechToTextStreamResponse_TurnUpdate_case case_SpeechToTextStreamResponse_Content = 2
const SpeechToTextStreamResponse_TurnEagerEnd_case case_SpeechToTextStreamResponse_Content = 3
const SpeechToTextStreamResponse_TurnResumed_case case_SpeechToTextStreamResponse_Content = 4
const SpeechToTextStreamResponse_TurnEnd_case case_SpeechToTextStreamResponse_Content = 5
const SpeechToTextStreamResponse_ModelUsage_case case_SpeechToTextStreamResponse_Content = 6
const SpeechToTextStreamResponse_GenerationMetrics_case case_SpeechToTextStreamResponse_Content = 7

func (x *SpeechToTextStreamResponse) WhichContent() case_SpeechToTextStreamResponse_Content {
	if x == nil {
		return SpeechToTextStreamResponse_Content_not_set_case
	}
	switch x.Content.(type) {
	case *SpeechToTextStreamResponse_TurnStart:
		return SpeechToTextStreamResponse_TurnStart_case
	case *SpeechToTextStreamResponse_TurnUpdate:
		return SpeechToTextStreamResponse_TurnUpdate_case
	case *SpeechToTextStreamResponse_TurnEagerEnd:
		return SpeechToTextStreamResponse_TurnEagerEnd_case
	case *SpeechToTextStreamResponse_TurnResumed:
		return SpeechToTextStreamResponse_TurnResumed_case
	case *SpeechToTextStreamResponse_TurnEnd:
		return SpeechToTextStreamResponse_TurnEnd_case
	case *SpeechToTextStreamResponse_ModelUsage:
		return SpeechToTextStreamResponse_ModelUsage_case
	case *SpeechToTextStreamResponse_GenerationMetrics:
		return SpeechToTextStreamResponse_GenerationMetrics_case
	default:
		return SpeechToTextStreamResponse_Content_not_set_case
	}
}

type SpeechToTextStreamResponse_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// Content of this response.

	// Fields of oneof Content:
	// Indicates the user has started speaking a new turn.
	TurnStart *SpeechToTextStreamTurnEvent
	// Provides a partial transcript update during an ongoing turn.
	TurnUpdate *SpeechToTextStreamTurnEvent
	// Indicates the model predicts the turn is likely ending (tentative, may be resumed).
	TurnEagerEnd *SpeechToTextStreamTurnEvent
	// Indicates a previously signaled eager end of turn was incorrect and the turn continues.
	TurnResumed *SpeechToTextStreamTurnEvent
	// Indicates the user's turn has definitively ended with a final transcript.
	TurnEnd *SpeechToTextStreamTurnEvent
	// Model usage metrics (sent at the end of the stream).
	ModelUsage *v11.ModelUsage
	// Generation metrics (sent at the end of the stream).
	GenerationMetrics *v11.GenerationMetrics
	// -- end of Content
}

func (b0 SpeechToTextStreamResponse_builder) Build() *SpeechToTextStreamResponse {
	m0 := &SpeechToTextStreamResponse{}
	b, x := &b0, m0
	_, _ = b, x
	if b.TurnStart != nil {
		x.Content = &SpeechToTextStreamResponse_TurnStart{b.TurnStart}
	}
	if b.TurnUpdate != nil {
		x.Content = &SpeechToTextStreamResponse_TurnUpdate{b.TurnUpdate}
	}
	if b.TurnEagerEnd != nil {
		x.Content = &SpeechToTextStreamResponse_TurnEagerEnd{b.TurnEagerEnd}
	}
	if b.TurnResumed != nil {
		x.Content = &SpeechToTextStreamResponse_TurnResumed{b.TurnResumed}
	}
	if b.TurnEnd != nil {
		x.Content = &SpeechToTextStreamResponse_TurnEnd{b.TurnEnd}
	}
	if b.ModelUsage != nil {
		x.Content = &SpeechToTextStreamResponse_ModelUsage{b.ModelUsage}
	}
	if b.GenerationMetrics != nil {
		x.Content = &SpeechToTextStreamResponse_GenerationMetrics{b.GenerationMetrics}
	}
	return m0
}

type case_SpeechToTextStreamResponse_Content protoreflect.FieldNumber

func (x case_SpeechToTextStreamResponse_Content) String() string {
	md := file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[6].Descriptor()
	if x == 0 {
		return "not set"
	}
	return protoimpl.X.MessageFieldStringOf(md, protoreflect.FieldNumber(x))
}

type isSpeechToTextStreamResponse_Content interface {
	isSpeechToTextStreamResponse_Content()
}

type SpeechToTextStreamResponse_TurnStart struct {
	// Indicates the user has started speaking a new turn.
	TurnStart *SpeechToTextStreamTurnEvent `protobuf:"bytes,1,opt,name=turn_start,json=turnStart,proto3,oneof"`
}

type SpeechToTextStreamResponse_TurnUpdate struct {
	// Provides a partial transcript update during an ongoing turn.
	TurnUpdate *SpeechToTextStreamTurnEvent `protobuf:"bytes,2,opt,name=turn_update,json=turnUpdate,proto3,oneof"`
}

type SpeechToTextStreamResponse_TurnEagerEnd struct {
	// Indicates the model predicts the turn is likely ending (tentative, may be resumed).
	TurnEagerEnd *SpeechToTextStreamTurnEvent `protobuf:"bytes,3,opt,name=turn_eager_end,json=turnEagerEnd,proto3,oneof"`
}

type SpeechToTextStreamResponse_TurnResumed struct {
	// Indicates a previously signaled eager end of turn was incorrect and the turn continues.
	TurnResumed *SpeechToTextStreamTurnEvent `protobuf:"bytes,4,opt,name=turn_resumed,json=turnResumed,proto3,oneof"`
}

type SpeechToTextStreamResponse_TurnEnd struct {
	// Indicates the user's turn has definitively ended with a final transcript.
	TurnEnd *SpeechToTextStreamTurnEvent `protobuf:"bytes,5,opt,name=turn_end,json=turnEnd,proto3,oneof"`
}

type SpeechToTextStreamResponse_ModelUsage struct {
	// Model usage metrics (sent at the end of the stream).
	ModelUsage *v11.ModelUsage `protobuf:"bytes,6,opt,name=model_usage,json=modelUsage,proto3,oneof"`
}

type SpeechToTextStreamResponse_GenerationMetrics struct {
	// Generation metrics (sent at the end of the stream).
	GenerationMetrics *v11.GenerationMetrics `protobuf:"bytes,7,opt,name=generation_metrics,json=generationMetrics,proto3,oneof"`
}

func (*SpeechToTextStreamResponse_TurnStart) isSpeechToTextStreamResponse_Content() {}

func (*SpeechToTextStreamResponse_TurnUpdate) isSpeechToTextStreamResponse_Content() {}

func (*SpeechToTextStreamResponse_TurnEagerEnd) isSpeechToTextStreamResponse_Content() {}

func (*SpeechToTextStreamResponse_TurnResumed) isSpeechToTextStreamResponse_Content() {}

func (*SpeechToTextStreamResponse_TurnEnd) isSpeechToTextStreamResponse_Content() {}

func (*SpeechToTextStreamResponse_ModelUsage) isSpeechToTextStreamResponse_Content() {}

func (*SpeechToTextStreamResponse_GenerationMetrics) isSpeechToTextStreamResponse_Content() {}

// Holds transcript events.
type SpeechToTextStreamTurnEvent struct {
	state protoimpl.MessageState `protogen:"hybrid.v1"`
	// Index of the turn this event belongs to, starts at zero.
	TurnIndex int32 `protobuf:"varint,1,opt,name=turn_index,json=turnIndex,proto3" json:"turn_index,omitempty"`
	// Transcript for this turn so far.
	Transcript string `protobuf:"bytes,2,opt,name=transcript,proto3" json:"transcript,omitempty"`
	// Confidence score (0.0 to 1.0) that this turn has ended.
	EndOfTurnConfidence float64 `protobuf:"fixed64,3,opt,name=end_of_turn_confidence,json=endOfTurnConfidence,proto3" json:"end_of_turn_confidence,omitempty"`
	unknownFields       protoimpl.UnknownFields
	sizeCache           protoimpl.SizeCache
}

func (x *SpeechToTextStreamTurnEvent) Reset() {
	*x = SpeechToTextStreamTurnEvent{}
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextStreamTurnEvent) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextStreamTurnEvent) ProtoMessage() {}

func (x *SpeechToTextStreamTurnEvent) ProtoReflect() protoreflect.Message {
	mi := &file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

func (x *SpeechToTextStreamTurnEvent) GetTurnIndex() int32 {
	if x != nil {
		return x.TurnIndex
	}
	return 0
}

func (x *SpeechToTextStreamTurnEvent) GetTranscript() string {
	if x != nil {
		return x.Transcript
	}
	return ""
}

func (x *SpeechToTextStreamTurnEvent) GetEndOfTurnConfidence() float64 {
	if x != nil {
		return x.EndOfTurnConfidence
	}
	return 0
}

func (x *SpeechToTextStreamTurnEvent) SetTurnIndex(v int32) {
	x.TurnIndex = v
}

func (x *SpeechToTextStreamTurnEvent) SetTranscript(v string) {
	x.Transcript = v
}

func (x *SpeechToTextStreamTurnEvent) SetEndOfTurnConfidence(v float64) {
	x.EndOfTurnConfidence = v
}

type SpeechToTextStreamTurnEvent_builder struct {
	_ [0]func() // Prevents comparability and use of unkeyed literals for the builder.

	// Index of the turn this event belongs to, starts at zero.
	TurnIndex int32
	// Transcript for this turn so far.
	Transcript string
	// Confidence score (0.0 to 1.0) that this turn has ended.
	EndOfTurnConfidence float64
}

func (b0 SpeechToTextStreamTurnEvent_builder) Build() *SpeechToTextStreamTurnEvent {
	m0 := &SpeechToTextStreamTurnEvent{}
	b, x := &b0, m0
	_, _ = b, x
	x.TurnIndex = b.TurnIndex
	x.Transcript = b.Transcript
	x.EndOfTurnConfidence = b.EndOfTurnConfidence
	return m0
}

var File_malonaz_ai_ai_service_v1_speech_to_text_proto protoreflect.FileDescriptor

const file_malonaz_ai_ai_service_v1_speech_to_text_proto_rawDesc = "" +
	"\n" +
	"-malonaz/ai/ai_service/v1/speech_to_text.proto\x12\x18malonaz.ai.ai_service.v1\x1a\x1bbuf/validate/validate.proto\x1a\x19google/api/resource.proto\x1a\x1egoogle/protobuf/duration.proto\x1a\x1bmalonaz/ai/v1/metrics.proto\x1a\x1cmalonaz/audio/v1/audio.proto\"\xf8\x01\n" +
	"\x13SpeechToTextRequest\x125\n" +
	"\x05model\x18\x01 \x01(\tB\x1f\xfaA\x16\n" +
	"\x14ai.malonaz.com/Model\xbaH\x03\xc8\x01\x01R\x05model\x12C\n" +
	"\faudio_format\x18\x02 \x01(\v2\x18.malonaz.audio.v1.FormatB\x06\xbaH\x03\xc8\x01\x01R\vaudioFormat\x12@\n" +
	"\vaudio_chunk\x18\x03 \x01(\v2\x17.malonaz.audio.v1.ChunkB\x06\xbaH\x03\xc8\x01\x01R\n" +
	"audioChunk\x12#\n" +
	"\rlanguage_code\x18\x04 \x01(\tR\flanguageCode\"\xc3\x01\n" +
	"\x14SpeechToTextResponse\x12\x1e\n" +
	"\n" +
	"transcript\x18\x01 \x01(\tR\n" +
	"transcript\x12:\n" +
	"\vmodel_usage\x18\x02 \x01(\v2\x19.malonaz.ai.v1.ModelUsageR\n" +
	"modelUsage\x12O\n" +
	"\x12generation_metrics\x18\x03 \x01(\v2 .malonaz.ai.v1.GenerationMetricsR\x11generationMetrics\"\xcc\x01\n" +
	"\x19SpeechToTextStreamRequest\x12a\n" +
	"\rconfiguration\x18\x01 \x01(\v29.malonaz.ai.ai_service.v1.SpeechToTextStreamConfigurationH\x00R\rconfiguration\x12:\n" +
	"\vaudio_chunk\x18\x02 \x01(\v2\x17.malonaz.audio.v1.ChunkH\x00R\n" +
	"audioChunkB\x10\n" +
	"\acontent\x12\x05\xbaH\x02\b\x01\"\x96\x03\n" +
	"\x1fSpeechToTextStreamConfiguration\x125\n" +
	"\x05model\x18\x01 \x01(\tB\x1f\xfaA\x16\n" +
	"\x14ai.malonaz.com/Model\xbaH\x03\xc8\x01\x01R\x05model\x12C\n" +
	"\faudio_format\x18\x02 \x01(\v2\x18.malonaz.audio.v1.FormatB\x06\xbaH\x03\xc8\x01\x01R\vaudioFormat\x12#\n" +
	"\rlanguage_code\x18\x03 \x01(\tR\flanguageCode\x12e\n" +
	"\vend_of_turn\x18\x04 \x01(\v2C.malonaz.ai.ai_service.v1.SpeechToTextStreamCommitStrategyEndOfTurnH\x00R\tendOfTurn\x12Q\n" +
	"\x03vad\x18\x05 \x01(\v2=.malonaz.ai.ai_service.v1.SpeechToTextStreamCommitStrategyVadH\x00R\x03vadB\x18\n" +
	"\x0fcommit_strategy\x12\x05\xbaH\x02\b\x01\"\xa4\x03\n" +
	")SpeechToTextStreamCommitStrategyEndOfTurn\x12J\n" +
	"\x14confidence_threshold\x18\x01 \x01(\x01B\x17\xbaH\x14\x12\x12\x19\x00\x00\x00\x00\x00\x00\xf0?)\x00\x00\x00\x00\x00\x00\x00\x00R\x13confidenceThreshold\x12U\n" +
	"\x1aeager_confidence_threshold\x18\x02 \x01(\x01B\x17\xbaH\x14\x12\x12\x19\x00\x00\x00\x00\x00\x00\xf0?)\x00\x00\x00\x00\x00\x00\x00\x00R\x18eagerConfidenceThreshold\x12A\n" +
	"\atimeout\x18\x03 \x01(\v2\x19.google.protobuf.DurationB\f\xbaH\t\xaa\x01\x06\"\x02\b\n" +
	"2\x00R\atimeout:\x90\x01\xbaH\x8c\x01\x1a\x89\x01\n" +
	"\reager_lte_eot\x12:eager_confidence_threshold must be <= confidence_threshold\x1a<this.eager_confidence_threshold <= this.confidence_threshold\"\xfd\x02\n" +
	"#SpeechToTextStreamCommitStrategyVad\x12Z\n" +
	"\x11silence_threshold\x18\x01 \x01(\v2\x19.google.protobuf.DurationB\x12\xbaH\x0f\xaa\x01\f\"\x02\b\x032\x06\x10\x80Æ†\x8f\x01R\x10silenceThreshold\x12<\n" +
	"\rvad_threshold\x18\x02 \x01(\x01B\x17\xbaH\x14\x12\x12\x19\xcd\xcc\xcc\xcc\xcc\xcc\xec?)\x9a\x99\x99\x99\x99\x99\xb9?R\fvadThreshold\x12\\\n" +
	"\x13min_speech_duration\x18\x03 \x01(\v2\x19.google.protobuf.DurationB\x11\xbaH\x0e\xaa\x01\v\"\x02\b\x022\x05\x10\x80\xe1\xeb\x17R\x11minSpeechDuration\x12^\n" +
	"\x14min_silence_duration\x18\x04 \x01(\v2\x19.google.protobuf.DurationB\x11\xbaH\x0e\xaa\x01\v\"\x02\b\x022\x05\x10\x80\xe1\xeb\x17R\x12minSilenceDuration\"\x80\x05\n" +
	"\x1aSpeechToTextStreamResponse\x12V\n" +
	"\n" +
	"turn_start\x18\x01 \x01(\v25.malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEventH\x00R\tturnStart\x12X\n" +
	"\vturn_update\x18\x02 \x01(\v25.malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEventH\x00R\n" +
	"turnUpdate\x12]\n" +
	"\x0eturn_eager_end\x18\x03 \x01(\v25.malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEventH\x00R\fturnEagerEnd\x12Z\n" +
	"\fturn_resumed\x18\x04 \x01(\v25.malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEventH\x00R\vturnResumed\x12R\n" +
	"\bturn_end\x18\x05 \x01(\v25.malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEventH\x00R\aturnEnd\x12<\n" +
	"\vmodel_usage\x18\x06 \x01(\v2\x19.malonaz.ai.v1.ModelUsageH\x00R\n" +
	"modelUsage\x12Q\n" +
	"\x12generation_metrics\x18\a \x01(\v2 .malonaz.ai.v1.GenerationMetricsH\x00R\x11generationMetricsB\x10\n" +
	"\acontent\x12\x05\xbaH\x02\b\x01\"\x91\x01\n" +
	"\x1bSpeechToTextStreamTurnEvent\x12\x1d\n" +
	"\n" +
	"turn_index\x18\x01 \x01(\x05R\tturnIndex\x12\x1e\n" +
	"\n" +
	"transcript\x18\x02 \x01(\tR\n" +
	"transcript\x123\n" +
	"\x16end_of_turn_confidence\x18\x03 \x01(\x01R\x13endOfTurnConfidenceB3Z1github.com/malonaz/core/genproto/ai/ai_service/v1b\x06proto3"

var file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes = make([]protoimpl.MessageInfo, 8)
var file_malonaz_ai_ai_service_v1_speech_to_text_proto_goTypes = []any{
	(*SpeechToTextRequest)(nil),                       // 0: malonaz.ai.ai_service.v1.SpeechToTextRequest
	(*SpeechToTextResponse)(nil),                      // 1: malonaz.ai.ai_service.v1.SpeechToTextResponse
	(*SpeechToTextStreamRequest)(nil),                 // 2: malonaz.ai.ai_service.v1.SpeechToTextStreamRequest
	(*SpeechToTextStreamConfiguration)(nil),           // 3: malonaz.ai.ai_service.v1.SpeechToTextStreamConfiguration
	(*SpeechToTextStreamCommitStrategyEndOfTurn)(nil), // 4: malonaz.ai.ai_service.v1.SpeechToTextStreamCommitStrategyEndOfTurn
	(*SpeechToTextStreamCommitStrategyVad)(nil),       // 5: malonaz.ai.ai_service.v1.SpeechToTextStreamCommitStrategyVad
	(*SpeechToTextStreamResponse)(nil),                // 6: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse
	(*SpeechToTextStreamTurnEvent)(nil),               // 7: malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	(*v1.Format)(nil),                                 // 8: malonaz.audio.v1.Format
	(*v1.Chunk)(nil),                                  // 9: malonaz.audio.v1.Chunk
	(*v11.ModelUsage)(nil),                            // 10: malonaz.ai.v1.ModelUsage
	(*v11.GenerationMetrics)(nil),                     // 11: malonaz.ai.v1.GenerationMetrics
	(*durationpb.Duration)(nil),                       // 12: google.protobuf.Duration
}
var file_malonaz_ai_ai_service_v1_speech_to_text_proto_depIdxs = []int32{
	8,  // 0: malonaz.ai.ai_service.v1.SpeechToTextRequest.audio_format:type_name -> malonaz.audio.v1.Format
	9,  // 1: malonaz.ai.ai_service.v1.SpeechToTextRequest.audio_chunk:type_name -> malonaz.audio.v1.Chunk
	10, // 2: malonaz.ai.ai_service.v1.SpeechToTextResponse.model_usage:type_name -> malonaz.ai.v1.ModelUsage
	11, // 3: malonaz.ai.ai_service.v1.SpeechToTextResponse.generation_metrics:type_name -> malonaz.ai.v1.GenerationMetrics
	3,  // 4: malonaz.ai.ai_service.v1.SpeechToTextStreamRequest.configuration:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamConfiguration
	9,  // 5: malonaz.ai.ai_service.v1.SpeechToTextStreamRequest.audio_chunk:type_name -> malonaz.audio.v1.Chunk
	8,  // 6: malonaz.ai.ai_service.v1.SpeechToTextStreamConfiguration.audio_format:type_name -> malonaz.audio.v1.Format
	4,  // 7: malonaz.ai.ai_service.v1.SpeechToTextStreamConfiguration.end_of_turn:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamCommitStrategyEndOfTurn
	5,  // 8: malonaz.ai.ai_service.v1.SpeechToTextStreamConfiguration.vad:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamCommitStrategyVad
	12, // 9: malonaz.ai.ai_service.v1.SpeechToTextStreamCommitStrategyEndOfTurn.timeout:type_name -> google.protobuf.Duration
	12, // 10: malonaz.ai.ai_service.v1.SpeechToTextStreamCommitStrategyVad.silence_threshold:type_name -> google.protobuf.Duration
	12, // 11: malonaz.ai.ai_service.v1.SpeechToTextStreamCommitStrategyVad.min_speech_duration:type_name -> google.protobuf.Duration
	12, // 12: malonaz.ai.ai_service.v1.SpeechToTextStreamCommitStrategyVad.min_silence_duration:type_name -> google.protobuf.Duration
	7,  // 13: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.turn_start:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	7,  // 14: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.turn_update:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	7,  // 15: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.turn_eager_end:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	7,  // 16: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.turn_resumed:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	7,  // 17: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.turn_end:type_name -> malonaz.ai.ai_service.v1.SpeechToTextStreamTurnEvent
	10, // 18: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.model_usage:type_name -> malonaz.ai.v1.ModelUsage
	11, // 19: malonaz.ai.ai_service.v1.SpeechToTextStreamResponse.generation_metrics:type_name -> malonaz.ai.v1.GenerationMetrics
	20, // [20:20] is the sub-list for method output_type
	20, // [20:20] is the sub-list for method input_type
	20, // [20:20] is the sub-list for extension type_name
	20, // [20:20] is the sub-list for extension extendee
	0,  // [0:20] is the sub-list for field type_name
}

func init() { file_malonaz_ai_ai_service_v1_speech_to_text_proto_init() }
func file_malonaz_ai_ai_service_v1_speech_to_text_proto_init() {
	if File_malonaz_ai_ai_service_v1_speech_to_text_proto != nil {
		return
	}
	file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[2].OneofWrappers = []any{
		(*SpeechToTextStreamRequest_Configuration)(nil),
		(*SpeechToTextStreamRequest_AudioChunk)(nil),
	}
	file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[3].OneofWrappers = []any{
		(*SpeechToTextStreamConfiguration_EndOfTurn)(nil),
		(*SpeechToTextStreamConfiguration_Vad)(nil),
	}
	file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes[6].OneofWrappers = []any{
		(*SpeechToTextStreamResponse_TurnStart)(nil),
		(*SpeechToTextStreamResponse_TurnUpdate)(nil),
		(*SpeechToTextStreamResponse_TurnEagerEnd)(nil),
		(*SpeechToTextStreamResponse_TurnResumed)(nil),
		(*SpeechToTextStreamResponse_TurnEnd)(nil),
		(*SpeechToTextStreamResponse_ModelUsage)(nil),
		(*SpeechToTextStreamResponse_GenerationMetrics)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_malonaz_ai_ai_service_v1_speech_to_text_proto_rawDesc), len(file_malonaz_ai_ai_service_v1_speech_to_text_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   8,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_malonaz_ai_ai_service_v1_speech_to_text_proto_goTypes,
		DependencyIndexes: file_malonaz_ai_ai_service_v1_speech_to_text_proto_depIdxs,
		MessageInfos:      file_malonaz_ai_ai_service_v1_speech_to_text_proto_msgTypes,
	}.Build()
	File_malonaz_ai_ai_service_v1_speech_to_text_proto = out.File
	file_malonaz_ai_ai_service_v1_speech_to_text_proto_goTypes = nil
	file_malonaz_ai_ai_service_v1_speech_to_text_proto_depIdxs = nil
}
