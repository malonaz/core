// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.9
// 	protoc        v6.30.0
// source: ai/ai_service/v1/ai_service.proto

package v1

import (
	_ "buf.build/gen/go/bufbuild/protovalidate/protocolbuffers/go/buf/validate"
	v1 "github.com/malonaz/core/genproto/ai/v1"
	v11 "github.com/malonaz/core/genproto/audio/v1"
	_ "google.golang.org/genproto/googleapis/api/annotations"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Request message for Ai.SpeechToText.
type SpeechToTextRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The model for this request.
	Model v1.Model `protobuf:"varint,1,opt,name=model,proto3,enum=malonaz.core.ai.v1.Model" json:"model,omitempty"`
	// Audio data in PCM format.
	Audio []byte `protobuf:"bytes,2,opt,name=audio,proto3" json:"audio,omitempty"`
	// Optional language code to improve transcription accuracy (e.g., "en", "es").
	Language      string `protobuf:"bytes,3,opt,name=language,proto3" json:"language,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SpeechToTextRequest) Reset() {
	*x = SpeechToTextRequest{}
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextRequest) ProtoMessage() {}

func (x *SpeechToTextRequest) ProtoReflect() protoreflect.Message {
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeechToTextRequest.ProtoReflect.Descriptor instead.
func (*SpeechToTextRequest) Descriptor() ([]byte, []int) {
	return file_ai_ai_service_v1_ai_service_proto_rawDescGZIP(), []int{0}
}

func (x *SpeechToTextRequest) GetModel() v1.Model {
	if x != nil {
		return x.Model
	}
	return v1.Model(0)
}

func (x *SpeechToTextRequest) GetAudio() []byte {
	if x != nil {
		return x.Audio
	}
	return nil
}

func (x *SpeechToTextRequest) GetLanguage() string {
	if x != nil {
		return x.Language
	}
	return ""
}

// Response message for Ai.SpeechToText.
type SpeechToTextResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The transcribed text.
	Transcript string `protobuf:"bytes,1,opt,name=transcript,proto3" json:"transcript,omitempty"`
	// Model usage metrics.
	ModelUsage *v1.ModelUsage `protobuf:"bytes,2,opt,name=model_usage,json=modelUsage,proto3" json:"model_usage,omitempty"`
	// Generation metrics.
	GenerationMetrics *v1.GenerationMetrics `protobuf:"bytes,3,opt,name=generation_metrics,json=generationMetrics,proto3" json:"generation_metrics,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *SpeechToTextResponse) Reset() {
	*x = SpeechToTextResponse{}
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SpeechToTextResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SpeechToTextResponse) ProtoMessage() {}

func (x *SpeechToTextResponse) ProtoReflect() protoreflect.Message {
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SpeechToTextResponse.ProtoReflect.Descriptor instead.
func (*SpeechToTextResponse) Descriptor() ([]byte, []int) {
	return file_ai_ai_service_v1_ai_service_proto_rawDescGZIP(), []int{1}
}

func (x *SpeechToTextResponse) GetTranscript() string {
	if x != nil {
		return x.Transcript
	}
	return ""
}

func (x *SpeechToTextResponse) GetModelUsage() *v1.ModelUsage {
	if x != nil {
		return x.ModelUsage
	}
	return nil
}

func (x *SpeechToTextResponse) GetGenerationMetrics() *v1.GenerationMetrics {
	if x != nil {
		return x.GenerationMetrics
	}
	return nil
}

// Request message for Ai.TextToText.
type TextToTextRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The model for this request.
	Model v1.Model `protobuf:"varint,1,opt,name=model,proto3,enum=malonaz.core.ai.v1.Model" json:"model,omitempty"`
	// The conversation messages.
	Messages []*v1.Message `protobuf:"bytes,2,rep,name=messages,proto3" json:"messages,omitempty"`
	// Tools available for the model to call.
	Tools []*v1.Tool `protobuf:"bytes,3,rep,name=tools,proto3" json:"tools,omitempty"`
	// For the model to use a tool.
	ToolChoice string `protobuf:"bytes,4,opt,name=tool_choice,json=toolChoice,proto3" json:"tool_choice,omitempty"`
	// Additional configuration.
	Configuration *TextToTextConfiguration `protobuf:"bytes,5,opt,name=configuration,proto3" json:"configuration,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TextToTextRequest) Reset() {
	*x = TextToTextRequest{}
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextToTextRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextToTextRequest) ProtoMessage() {}

func (x *TextToTextRequest) ProtoReflect() protoreflect.Message {
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextToTextRequest.ProtoReflect.Descriptor instead.
func (*TextToTextRequest) Descriptor() ([]byte, []int) {
	return file_ai_ai_service_v1_ai_service_proto_rawDescGZIP(), []int{2}
}

func (x *TextToTextRequest) GetModel() v1.Model {
	if x != nil {
		return x.Model
	}
	return v1.Model(0)
}

func (x *TextToTextRequest) GetMessages() []*v1.Message {
	if x != nil {
		return x.Messages
	}
	return nil
}

func (x *TextToTextRequest) GetTools() []*v1.Tool {
	if x != nil {
		return x.Tools
	}
	return nil
}

func (x *TextToTextRequest) GetToolChoice() string {
	if x != nil {
		return x.ToolChoice
	}
	return ""
}

func (x *TextToTextRequest) GetConfiguration() *TextToTextConfiguration {
	if x != nil {
		return x.Configuration
	}
	return nil
}

// Configuration for text to text generation.
type TextToTextConfiguration struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Maximum number of tokens to generate. Includes reasoning tokens.
	MaxTokens int64 `protobuf:"varint,1,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`
	// Sampling temperature (0.0 to 2.0).
	Temperature float64 `protobuf:"fixed64,2,opt,name=temperature,proto3" json:"temperature,omitempty"`
	// Represents the level of reasoning effort for AI model responses.
	// The reasoning effort parameter guides the model on how many reasoning tokens
	// to generate before creating a response to the prompt. Higher effort levels
	// result in more thorough reasoning at the cost of speed and token usage.
	ReasoningEffort v1.ReasoningEffort `protobuf:"varint,3,opt,name=reasoning_effort,json=reasoningEffort,proto3,enum=malonaz.core.ai.v1.ReasoningEffort" json:"reasoning_effort,omitempty"`
	// If true, we attempt to clean the output to extract a json object.
	// Fails the request if a json object cannot be found.
	ExtractJsonObject bool `protobuf:"varint,4,opt,name=extract_json_object,json=extractJsonObject,proto3" json:"extract_json_object,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *TextToTextConfiguration) Reset() {
	*x = TextToTextConfiguration{}
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextToTextConfiguration) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextToTextConfiguration) ProtoMessage() {}

func (x *TextToTextConfiguration) ProtoReflect() protoreflect.Message {
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextToTextConfiguration.ProtoReflect.Descriptor instead.
func (*TextToTextConfiguration) Descriptor() ([]byte, []int) {
	return file_ai_ai_service_v1_ai_service_proto_rawDescGZIP(), []int{3}
}

func (x *TextToTextConfiguration) GetMaxTokens() int64 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *TextToTextConfiguration) GetTemperature() float64 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *TextToTextConfiguration) GetReasoningEffort() v1.ReasoningEffort {
	if x != nil {
		return x.ReasoningEffort
	}
	return v1.ReasoningEffort(0)
}

func (x *TextToTextConfiguration) GetExtractJsonObject() bool {
	if x != nil {
		return x.ExtractJsonObject
	}
	return false
}

// Response message for Ai.TextToText.
type TextToTextResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The generated message.
	Message *v1.Message `protobuf:"bytes,1,opt,name=message,proto3" json:"message,omitempty"`
	// Model usage metrics.
	ModelUsage *v1.ModelUsage `protobuf:"bytes,2,opt,name=model_usage,json=modelUsage,proto3" json:"model_usage,omitempty"`
	// Generation metrics.
	GenerationMetrics *v1.GenerationMetrics `protobuf:"bytes,3,opt,name=generation_metrics,json=generationMetrics,proto3" json:"generation_metrics,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *TextToTextResponse) Reset() {
	*x = TextToTextResponse{}
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextToTextResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextToTextResponse) ProtoMessage() {}

func (x *TextToTextResponse) ProtoReflect() protoreflect.Message {
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextToTextResponse.ProtoReflect.Descriptor instead.
func (*TextToTextResponse) Descriptor() ([]byte, []int) {
	return file_ai_ai_service_v1_ai_service_proto_rawDescGZIP(), []int{4}
}

func (x *TextToTextResponse) GetMessage() *v1.Message {
	if x != nil {
		return x.Message
	}
	return nil
}

func (x *TextToTextResponse) GetModelUsage() *v1.ModelUsage {
	if x != nil {
		return x.ModelUsage
	}
	return nil
}

func (x *TextToTextResponse) GetGenerationMetrics() *v1.GenerationMetrics {
	if x != nil {
		return x.GenerationMetrics
	}
	return nil
}

// Request message for Ai.TextToSpeech.
type TextToSpeechRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The model for this request.
	Model v1.Model `protobuf:"varint,1,opt,name=model,proto3,enum=malonaz.core.ai.v1.Model" json:"model,omitempty"`
	// The text to convert to speech.
	Text string `protobuf:"bytes,2,opt,name=text,proto3" json:"text,omitempty"`
	// Voice identifier to use for speech generation.
	Voice         string `protobuf:"bytes,3,opt,name=voice,proto3" json:"voice,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TextToSpeechRequest) Reset() {
	*x = TextToSpeechRequest{}
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextToSpeechRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextToSpeechRequest) ProtoMessage() {}

func (x *TextToSpeechRequest) ProtoReflect() protoreflect.Message {
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextToSpeechRequest.ProtoReflect.Descriptor instead.
func (*TextToSpeechRequest) Descriptor() ([]byte, []int) {
	return file_ai_ai_service_v1_ai_service_proto_rawDescGZIP(), []int{5}
}

func (x *TextToSpeechRequest) GetModel() v1.Model {
	if x != nil {
		return x.Model
	}
	return v1.Model(0)
}

func (x *TextToSpeechRequest) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

func (x *TextToSpeechRequest) GetVoice() string {
	if x != nil {
		return x.Voice
	}
	return ""
}

// Response message for Ai.TextToSpeech.
type TextToSpeechResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Audio format of the audio.
	AudioFormat *v11.Format `protobuf:"bytes,1,opt,name=audio_format,json=audioFormat,proto3" json:"audio_format,omitempty"`
	// Audio data chunk in PCM16 format.
	AudioChunk *v11.Chunk `protobuf:"bytes,2,opt,name=audio_chunk,json=audioChunk,proto3" json:"audio_chunk,omitempty"`
	// Model usage metrics.
	ModelUsage *v1.ModelUsage `protobuf:"bytes,3,opt,name=model_usage,json=modelUsage,proto3" json:"model_usage,omitempty"`
	// Generation metrics.
	GenerationMetrics *v1.GenerationMetrics `protobuf:"bytes,4,opt,name=generation_metrics,json=generationMetrics,proto3" json:"generation_metrics,omitempty"`
	unknownFields     protoimpl.UnknownFields
	sizeCache         protoimpl.SizeCache
}

func (x *TextToSpeechResponse) Reset() {
	*x = TextToSpeechResponse{}
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextToSpeechResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextToSpeechResponse) ProtoMessage() {}

func (x *TextToSpeechResponse) ProtoReflect() protoreflect.Message {
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextToSpeechResponse.ProtoReflect.Descriptor instead.
func (*TextToSpeechResponse) Descriptor() ([]byte, []int) {
	return file_ai_ai_service_v1_ai_service_proto_rawDescGZIP(), []int{6}
}

func (x *TextToSpeechResponse) GetAudioFormat() *v11.Format {
	if x != nil {
		return x.AudioFormat
	}
	return nil
}

func (x *TextToSpeechResponse) GetAudioChunk() *v11.Chunk {
	if x != nil {
		return x.AudioChunk
	}
	return nil
}

func (x *TextToSpeechResponse) GetModelUsage() *v1.ModelUsage {
	if x != nil {
		return x.ModelUsage
	}
	return nil
}

func (x *TextToSpeechResponse) GetGenerationMetrics() *v1.GenerationMetrics {
	if x != nil {
		return x.GenerationMetrics
	}
	return nil
}

// Request message for Ai.TextToSpeechStream.
type TextToSpeechStreamRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The model for this request.
	Model v1.Model `protobuf:"varint,1,opt,name=model,proto3,enum=malonaz.core.ai.v1.Model" json:"model,omitempty"`
	// The text to convert to speech.
	Text string `protobuf:"bytes,2,opt,name=text,proto3" json:"text,omitempty"`
	// Voice identifier to use for speech generation.
	Voice         string `protobuf:"bytes,3,opt,name=voice,proto3" json:"voice,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TextToSpeechStreamRequest) Reset() {
	*x = TextToSpeechStreamRequest{}
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextToSpeechStreamRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextToSpeechStreamRequest) ProtoMessage() {}

func (x *TextToSpeechStreamRequest) ProtoReflect() protoreflect.Message {
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextToSpeechStreamRequest.ProtoReflect.Descriptor instead.
func (*TextToSpeechStreamRequest) Descriptor() ([]byte, []int) {
	return file_ai_ai_service_v1_ai_service_proto_rawDescGZIP(), []int{7}
}

func (x *TextToSpeechStreamRequest) GetModel() v1.Model {
	if x != nil {
		return x.Model
	}
	return v1.Model(0)
}

func (x *TextToSpeechStreamRequest) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

func (x *TextToSpeechStreamRequest) GetVoice() string {
	if x != nil {
		return x.Voice
	}
	return ""
}

// Response message for Ai.TextToSpeechStream.
type TextToSpeechStreamResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Content of this response.
	//
	// Types that are valid to be assigned to Content:
	//
	//	*TextToSpeechStreamResponse_AudioFormat
	//	*TextToSpeechStreamResponse_AudioChunk
	//	*TextToSpeechStreamResponse_ModelUsage
	//	*TextToSpeechStreamResponse_GenerationMetrics
	Content       isTextToSpeechStreamResponse_Content `protobuf_oneof:"content"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TextToSpeechStreamResponse) Reset() {
	*x = TextToSpeechStreamResponse{}
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TextToSpeechStreamResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TextToSpeechStreamResponse) ProtoMessage() {}

func (x *TextToSpeechStreamResponse) ProtoReflect() protoreflect.Message {
	mi := &file_ai_ai_service_v1_ai_service_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TextToSpeechStreamResponse.ProtoReflect.Descriptor instead.
func (*TextToSpeechStreamResponse) Descriptor() ([]byte, []int) {
	return file_ai_ai_service_v1_ai_service_proto_rawDescGZIP(), []int{8}
}

func (x *TextToSpeechStreamResponse) GetContent() isTextToSpeechStreamResponse_Content {
	if x != nil {
		return x.Content
	}
	return nil
}

func (x *TextToSpeechStreamResponse) GetAudioFormat() *v11.Format {
	if x != nil {
		if x, ok := x.Content.(*TextToSpeechStreamResponse_AudioFormat); ok {
			return x.AudioFormat
		}
	}
	return nil
}

func (x *TextToSpeechStreamResponse) GetAudioChunk() *v11.Chunk {
	if x != nil {
		if x, ok := x.Content.(*TextToSpeechStreamResponse_AudioChunk); ok {
			return x.AudioChunk
		}
	}
	return nil
}

func (x *TextToSpeechStreamResponse) GetModelUsage() *v1.ModelUsage {
	if x != nil {
		if x, ok := x.Content.(*TextToSpeechStreamResponse_ModelUsage); ok {
			return x.ModelUsage
		}
	}
	return nil
}

func (x *TextToSpeechStreamResponse) GetGenerationMetrics() *v1.GenerationMetrics {
	if x != nil {
		if x, ok := x.Content.(*TextToSpeechStreamResponse_GenerationMetrics); ok {
			return x.GenerationMetrics
		}
	}
	return nil
}

type isTextToSpeechStreamResponse_Content interface {
	isTextToSpeechStreamResponse_Content()
}

type TextToSpeechStreamResponse_AudioFormat struct {
	// Audio format of the audio stream.
	AudioFormat *v11.Format `protobuf:"bytes,1,opt,name=audio_format,json=audioFormat,proto3,oneof"`
}

type TextToSpeechStreamResponse_AudioChunk struct {
	// Audio data chunk in PCM16 format.
	AudioChunk *v11.Chunk `protobuf:"bytes,2,opt,name=audio_chunk,json=audioChunk,proto3,oneof"`
}

type TextToSpeechStreamResponse_ModelUsage struct {
	// Model usage event (sent last).
	ModelUsage *v1.ModelUsage `protobuf:"bytes,3,opt,name=model_usage,json=modelUsage,proto3,oneof"`
}

type TextToSpeechStreamResponse_GenerationMetrics struct {
	// Generation metrics.
	GenerationMetrics *v1.GenerationMetrics `protobuf:"bytes,4,opt,name=generation_metrics,json=generationMetrics,proto3,oneof"`
}

func (*TextToSpeechStreamResponse_AudioFormat) isTextToSpeechStreamResponse_Content() {}

func (*TextToSpeechStreamResponse_AudioChunk) isTextToSpeechStreamResponse_Content() {}

func (*TextToSpeechStreamResponse_ModelUsage) isTextToSpeechStreamResponse_Content() {}

func (*TextToSpeechStreamResponse_GenerationMetrics) isTextToSpeechStreamResponse_Content() {}

var File_ai_ai_service_v1_ai_service_proto protoreflect.FileDescriptor

const file_ai_ai_service_v1_ai_service_proto_rawDesc = "" +
	"\n" +
	"!ai/ai_service/v1/ai_service.proto\x12\x1dmalonaz.core.ai.ai_service.v1\x1a\x13ai/v1/message.proto\x1a\x13ai/v1/metrics.proto\x1a\x11ai/v1/model.proto\x1a\x10ai/v1/tool.proto\x1a\x14audio/v1/audio.proto\x1a\x1bbuf/validate/validate.proto\x1a\x1cgoogle/api/annotations.proto\x1a\x17google/api/client.proto\"\x8c\x01\n" +
	"\x13SpeechToTextRequest\x12;\n" +
	"\x05model\x18\x01 \x01(\x0e2\x19.malonaz.core.ai.v1.ModelB\n" +
	"\xbaH\a\x82\x01\x04\x10\x01 \x00R\x05model\x12\x1c\n" +
	"\x05audio\x18\x02 \x01(\fB\x06\xbaH\x03\xc8\x01\x01R\x05audio\x12\x1a\n" +
	"\blanguage\x18\x03 \x01(\tR\blanguage\"\xcd\x01\n" +
	"\x14SpeechToTextResponse\x12\x1e\n" +
	"\n" +
	"transcript\x18\x01 \x01(\tR\n" +
	"transcript\x12?\n" +
	"\vmodel_usage\x18\x02 \x01(\v2\x1e.malonaz.core.ai.v1.ModelUsageR\n" +
	"modelUsage\x12T\n" +
	"\x12generation_metrics\x18\x03 \x01(\v2%.malonaz.core.ai.v1.GenerationMetricsR\x11generationMetrics\"\xc2\x02\n" +
	"\x11TextToTextRequest\x12;\n" +
	"\x05model\x18\x01 \x01(\x0e2\x19.malonaz.core.ai.v1.ModelB\n" +
	"\xbaH\a\x82\x01\x04\x10\x01 \x00R\x05model\x12A\n" +
	"\bmessages\x18\x02 \x03(\v2\x1b.malonaz.core.ai.v1.MessageB\b\xbaH\x05\x92\x01\x02\b\x01R\bmessages\x12.\n" +
	"\x05tools\x18\x03 \x03(\v2\x18.malonaz.core.ai.v1.ToolR\x05tools\x12\x1f\n" +
	"\vtool_choice\x18\x04 \x01(\tR\n" +
	"toolChoice\x12\\\n" +
	"\rconfiguration\x18\x05 \x01(\v26.malonaz.core.ai.ai_service.v1.TextToTextConfigurationR\rconfiguration\"\xfc\x01\n" +
	"\x17TextToTextConfiguration\x12&\n" +
	"\n" +
	"max_tokens\x18\x01 \x01(\x03B\a\xbaH\x04\"\x02(\x00R\tmaxTokens\x129\n" +
	"\vtemperature\x18\x02 \x01(\x01B\x17\xbaH\x14\x12\x12\x19\x00\x00\x00\x00\x00\x00\x00@)\x00\x00\x00\x00\x00\x00\x00\x00R\vtemperature\x12N\n" +
	"\x10reasoning_effort\x18\x03 \x01(\x0e2#.malonaz.core.ai.v1.ReasoningEffortR\x0freasoningEffort\x12.\n" +
	"\x13extract_json_object\x18\x04 \x01(\bR\x11extractJsonObject\"\xe2\x01\n" +
	"\x12TextToTextResponse\x125\n" +
	"\amessage\x18\x01 \x01(\v2\x1b.malonaz.core.ai.v1.MessageR\amessage\x12?\n" +
	"\vmodel_usage\x18\x02 \x01(\v2\x1e.malonaz.core.ai.v1.ModelUsageR\n" +
	"modelUsage\x12T\n" +
	"\x12generation_metrics\x18\x03 \x01(\v2%.malonaz.core.ai.v1.GenerationMetricsR\x11generationMetrics\"\x8e\x01\n" +
	"\x13TextToSpeechRequest\x12;\n" +
	"\x05model\x18\x01 \x01(\x0e2\x19.malonaz.core.ai.v1.ModelB\n" +
	"\xbaH\a\x82\x01\x04\x10\x01 \x00R\x05model\x12\x1b\n" +
	"\x04text\x18\x02 \x01(\tB\a\xbaH\x04r\x02\x10\x01R\x04text\x12\x1d\n" +
	"\x05voice\x18\x03 \x01(\tB\a\xbaH\x04r\x02\x10\x01R\x05voice\"\xae\x02\n" +
	"\x14TextToSpeechResponse\x12@\n" +
	"\faudio_format\x18\x01 \x01(\v2\x1d.malonaz.core.audio.v1.FormatR\vaudioFormat\x12=\n" +
	"\vaudio_chunk\x18\x02 \x01(\v2\x1c.malonaz.core.audio.v1.ChunkR\n" +
	"audioChunk\x12?\n" +
	"\vmodel_usage\x18\x03 \x01(\v2\x1e.malonaz.core.ai.v1.ModelUsageR\n" +
	"modelUsage\x12T\n" +
	"\x12generation_metrics\x18\x04 \x01(\v2%.malonaz.core.ai.v1.GenerationMetricsR\x11generationMetrics\"\x94\x01\n" +
	"\x19TextToSpeechStreamRequest\x12;\n" +
	"\x05model\x18\x01 \x01(\x0e2\x19.malonaz.core.ai.v1.ModelB\n" +
	"\xbaH\a\x82\x01\x04\x10\x01 \x00R\x05model\x12\x1b\n" +
	"\x04text\x18\x02 \x01(\tB\a\xbaH\x04r\x02\x10\x01R\x04text\x12\x1d\n" +
	"\x05voice\x18\x03 \x01(\tB\a\xbaH\x04r\x02\x10\x01R\x05voice\"\xce\x02\n" +
	"\x1aTextToSpeechStreamResponse\x12B\n" +
	"\faudio_format\x18\x01 \x01(\v2\x1d.malonaz.core.audio.v1.FormatH\x00R\vaudioFormat\x12?\n" +
	"\vaudio_chunk\x18\x02 \x01(\v2\x1c.malonaz.core.audio.v1.ChunkH\x00R\n" +
	"audioChunk\x12A\n" +
	"\vmodel_usage\x18\x03 \x01(\v2\x1e.malonaz.core.ai.v1.ModelUsageH\x00R\n" +
	"modelUsage\x12V\n" +
	"\x12generation_metrics\x18\x04 \x01(\v2%.malonaz.core.ai.v1.GenerationMetricsH\x00R\x11generationMetricsB\x10\n" +
	"\acontent\x12\x05\xbaH\x02\b\x012\x8e\x05\n" +
	"\x02Ai\x12\x96\x01\n" +
	"\fSpeechToText\x122.malonaz.core.ai.ai_service.v1.SpeechToTextRequest\x1a3.malonaz.core.ai.ai_service.v1.SpeechToTextResponse\"\x1d\x82\xd3\xe4\x93\x02\x17:\x01*\"\x12/v1/speech-to-text\x12\x8e\x01\n" +
	"\n" +
	"TextToText\x120.malonaz.core.ai.ai_service.v1.TextToTextRequest\x1a1.malonaz.core.ai.ai_service.v1.TextToTextResponse\"\x1b\x82\xd3\xe4\x93\x02\x15:\x01*\"\x10/v1/text-to-text\x12\x96\x01\n" +
	"\fTextToSpeech\x122.malonaz.core.ai.ai_service.v1.TextToSpeechRequest\x1a3.malonaz.core.ai.ai_service.v1.TextToSpeechResponse\"\x1d\x82\xd3\xe4\x93\x02\x17:\x01*\"\x12/v1/text-to-speech\x12\xb1\x01\n" +
	"\x12TextToSpeechStream\x128.malonaz.core.ai.ai_service.v1.TextToSpeechStreamRequest\x1a9.malonaz.core.ai.ai_service.v1.TextToSpeechStreamResponse\"$\x82\xd3\xe4\x93\x02\x1e:\x01*\"\x19/v1/text-to-speech:stream0\x01\x1a\x11\xcaA\x0eai.malonaz.comB3Z1github.com/malonaz/core/genproto/ai/ai_service/v1b\x06proto3"

var (
	file_ai_ai_service_v1_ai_service_proto_rawDescOnce sync.Once
	file_ai_ai_service_v1_ai_service_proto_rawDescData []byte
)

func file_ai_ai_service_v1_ai_service_proto_rawDescGZIP() []byte {
	file_ai_ai_service_v1_ai_service_proto_rawDescOnce.Do(func() {
		file_ai_ai_service_v1_ai_service_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_ai_ai_service_v1_ai_service_proto_rawDesc), len(file_ai_ai_service_v1_ai_service_proto_rawDesc)))
	})
	return file_ai_ai_service_v1_ai_service_proto_rawDescData
}

var file_ai_ai_service_v1_ai_service_proto_msgTypes = make([]protoimpl.MessageInfo, 9)
var file_ai_ai_service_v1_ai_service_proto_goTypes = []any{
	(*SpeechToTextRequest)(nil),        // 0: malonaz.core.ai.ai_service.v1.SpeechToTextRequest
	(*SpeechToTextResponse)(nil),       // 1: malonaz.core.ai.ai_service.v1.SpeechToTextResponse
	(*TextToTextRequest)(nil),          // 2: malonaz.core.ai.ai_service.v1.TextToTextRequest
	(*TextToTextConfiguration)(nil),    // 3: malonaz.core.ai.ai_service.v1.TextToTextConfiguration
	(*TextToTextResponse)(nil),         // 4: malonaz.core.ai.ai_service.v1.TextToTextResponse
	(*TextToSpeechRequest)(nil),        // 5: malonaz.core.ai.ai_service.v1.TextToSpeechRequest
	(*TextToSpeechResponse)(nil),       // 6: malonaz.core.ai.ai_service.v1.TextToSpeechResponse
	(*TextToSpeechStreamRequest)(nil),  // 7: malonaz.core.ai.ai_service.v1.TextToSpeechStreamRequest
	(*TextToSpeechStreamResponse)(nil), // 8: malonaz.core.ai.ai_service.v1.TextToSpeechStreamResponse
	(v1.Model)(0),                      // 9: malonaz.core.ai.v1.Model
	(*v1.ModelUsage)(nil),              // 10: malonaz.core.ai.v1.ModelUsage
	(*v1.GenerationMetrics)(nil),       // 11: malonaz.core.ai.v1.GenerationMetrics
	(*v1.Message)(nil),                 // 12: malonaz.core.ai.v1.Message
	(*v1.Tool)(nil),                    // 13: malonaz.core.ai.v1.Tool
	(v1.ReasoningEffort)(0),            // 14: malonaz.core.ai.v1.ReasoningEffort
	(*v11.Format)(nil),                 // 15: malonaz.core.audio.v1.Format
	(*v11.Chunk)(nil),                  // 16: malonaz.core.audio.v1.Chunk
}
var file_ai_ai_service_v1_ai_service_proto_depIdxs = []int32{
	9,  // 0: malonaz.core.ai.ai_service.v1.SpeechToTextRequest.model:type_name -> malonaz.core.ai.v1.Model
	10, // 1: malonaz.core.ai.ai_service.v1.SpeechToTextResponse.model_usage:type_name -> malonaz.core.ai.v1.ModelUsage
	11, // 2: malonaz.core.ai.ai_service.v1.SpeechToTextResponse.generation_metrics:type_name -> malonaz.core.ai.v1.GenerationMetrics
	9,  // 3: malonaz.core.ai.ai_service.v1.TextToTextRequest.model:type_name -> malonaz.core.ai.v1.Model
	12, // 4: malonaz.core.ai.ai_service.v1.TextToTextRequest.messages:type_name -> malonaz.core.ai.v1.Message
	13, // 5: malonaz.core.ai.ai_service.v1.TextToTextRequest.tools:type_name -> malonaz.core.ai.v1.Tool
	3,  // 6: malonaz.core.ai.ai_service.v1.TextToTextRequest.configuration:type_name -> malonaz.core.ai.ai_service.v1.TextToTextConfiguration
	14, // 7: malonaz.core.ai.ai_service.v1.TextToTextConfiguration.reasoning_effort:type_name -> malonaz.core.ai.v1.ReasoningEffort
	12, // 8: malonaz.core.ai.ai_service.v1.TextToTextResponse.message:type_name -> malonaz.core.ai.v1.Message
	10, // 9: malonaz.core.ai.ai_service.v1.TextToTextResponse.model_usage:type_name -> malonaz.core.ai.v1.ModelUsage
	11, // 10: malonaz.core.ai.ai_service.v1.TextToTextResponse.generation_metrics:type_name -> malonaz.core.ai.v1.GenerationMetrics
	9,  // 11: malonaz.core.ai.ai_service.v1.TextToSpeechRequest.model:type_name -> malonaz.core.ai.v1.Model
	15, // 12: malonaz.core.ai.ai_service.v1.TextToSpeechResponse.audio_format:type_name -> malonaz.core.audio.v1.Format
	16, // 13: malonaz.core.ai.ai_service.v1.TextToSpeechResponse.audio_chunk:type_name -> malonaz.core.audio.v1.Chunk
	10, // 14: malonaz.core.ai.ai_service.v1.TextToSpeechResponse.model_usage:type_name -> malonaz.core.ai.v1.ModelUsage
	11, // 15: malonaz.core.ai.ai_service.v1.TextToSpeechResponse.generation_metrics:type_name -> malonaz.core.ai.v1.GenerationMetrics
	9,  // 16: malonaz.core.ai.ai_service.v1.TextToSpeechStreamRequest.model:type_name -> malonaz.core.ai.v1.Model
	15, // 17: malonaz.core.ai.ai_service.v1.TextToSpeechStreamResponse.audio_format:type_name -> malonaz.core.audio.v1.Format
	16, // 18: malonaz.core.ai.ai_service.v1.TextToSpeechStreamResponse.audio_chunk:type_name -> malonaz.core.audio.v1.Chunk
	10, // 19: malonaz.core.ai.ai_service.v1.TextToSpeechStreamResponse.model_usage:type_name -> malonaz.core.ai.v1.ModelUsage
	11, // 20: malonaz.core.ai.ai_service.v1.TextToSpeechStreamResponse.generation_metrics:type_name -> malonaz.core.ai.v1.GenerationMetrics
	0,  // 21: malonaz.core.ai.ai_service.v1.Ai.SpeechToText:input_type -> malonaz.core.ai.ai_service.v1.SpeechToTextRequest
	2,  // 22: malonaz.core.ai.ai_service.v1.Ai.TextToText:input_type -> malonaz.core.ai.ai_service.v1.TextToTextRequest
	5,  // 23: malonaz.core.ai.ai_service.v1.Ai.TextToSpeech:input_type -> malonaz.core.ai.ai_service.v1.TextToSpeechRequest
	7,  // 24: malonaz.core.ai.ai_service.v1.Ai.TextToSpeechStream:input_type -> malonaz.core.ai.ai_service.v1.TextToSpeechStreamRequest
	1,  // 25: malonaz.core.ai.ai_service.v1.Ai.SpeechToText:output_type -> malonaz.core.ai.ai_service.v1.SpeechToTextResponse
	4,  // 26: malonaz.core.ai.ai_service.v1.Ai.TextToText:output_type -> malonaz.core.ai.ai_service.v1.TextToTextResponse
	6,  // 27: malonaz.core.ai.ai_service.v1.Ai.TextToSpeech:output_type -> malonaz.core.ai.ai_service.v1.TextToSpeechResponse
	8,  // 28: malonaz.core.ai.ai_service.v1.Ai.TextToSpeechStream:output_type -> malonaz.core.ai.ai_service.v1.TextToSpeechStreamResponse
	25, // [25:29] is the sub-list for method output_type
	21, // [21:25] is the sub-list for method input_type
	21, // [21:21] is the sub-list for extension type_name
	21, // [21:21] is the sub-list for extension extendee
	0,  // [0:21] is the sub-list for field type_name
}

func init() { file_ai_ai_service_v1_ai_service_proto_init() }
func file_ai_ai_service_v1_ai_service_proto_init() {
	if File_ai_ai_service_v1_ai_service_proto != nil {
		return
	}
	file_ai_ai_service_v1_ai_service_proto_msgTypes[8].OneofWrappers = []any{
		(*TextToSpeechStreamResponse_AudioFormat)(nil),
		(*TextToSpeechStreamResponse_AudioChunk)(nil),
		(*TextToSpeechStreamResponse_ModelUsage)(nil),
		(*TextToSpeechStreamResponse_GenerationMetrics)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_ai_ai_service_v1_ai_service_proto_rawDesc), len(file_ai_ai_service_v1_ai_service_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   9,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_ai_ai_service_v1_ai_service_proto_goTypes,
		DependencyIndexes: file_ai_ai_service_v1_ai_service_proto_depIdxs,
		MessageInfos:      file_ai_ai_service_v1_ai_service_proto_msgTypes,
	}.Build()
	File_ai_ai_service_v1_ai_service_proto = out.File
	file_ai_ai_service_v1_ai_service_proto_goTypes = nil
	file_ai_ai_service_v1_ai_service_proto_depIdxs = nil
}
