syntax = "proto3";

package malonaz.ai.ai_service.v1;

import "buf/validate/validate.proto";
import "google/api/resource.proto";
import "google/protobuf/duration.proto";
import "malonaz/ai/v1/metrics.proto";
import "malonaz/audio/v1/audio.proto";

option go_package = "github.com/malonaz/core/genproto/ai/ai_service/v1";

// Request message for AiService.SpeechToText.
message SpeechToTextRequest {
  // The resource name of the model used.
  // Format: providers/{provider}/models/{model}
  string model = 1 [
    (google.api.resource_reference).type = "ai.malonaz.com/Model",
    (buf.validate.field).required = true
  ];

  // Audio format of the audio.
  audio.v1.Format audio_format = 2 [(buf.validate.field).required = true];

  // Audio to transcribe.
  audio.v1.Chunk audio_chunk = 3 [(buf.validate.field).required = true];

  // Optional language code to improve transcription accuracy (e.g., "en", "es").
  string language_code = 4;
}

// Response message for AiService.SpeechToText.
message SpeechToTextResponse {
  // The transcribed text.
  string transcript = 1;

  // Model usage metrics.
  .malonaz.ai.v1.ModelUsage model_usage = 2;

  // Generation metrics.
  .malonaz.ai.v1.GenerationMetrics generation_metrics = 3;
}

// Request message for AiService.SpeechToTextStream.
message SpeechToTextStreamRequest {
  // Content of this request.
  oneof content {
    option (buf.validate.oneof).required = true;

    // Configuration for the stream. Must be sent first.
    SpeechToTextStreamConfiguration configuration = 1;

    // Audio data chunk.
    audio.v1.Chunk audio_chunk = 2;
  }
}

// Configuration for speech to text streaming. Sent as the first message.
message SpeechToTextStreamConfiguration {
  // The resource name of the model used.
  // Format: providers/{provider}/models/{model}
  string model = 1 [
    (google.api.resource_reference).type = "ai.malonaz.com/Model",
    (buf.validate.field).required = true
  ];

  // Audio format of the audio stream.
  audio.v1.Format audio_format = 2 [(buf.validate.field).required = true];

  // Optional language code to improve transcription accuracy (e.g., "en", "es").
  string language_code = 3;

  // Strategy for committing transcript segments.
  oneof commit_strategy {
    option (buf.validate.oneof).required = true;
    // End of turn configuration.
    SpeechToTextStreamCommitStrategyEndOfTurn end_of_turn = 4;
    // Vad configuration.
    SpeechToTextStreamCommitStrategyVad vad = 5;
  }
}

// Configuration for end-of-turn detection.
message SpeechToTextStreamCommitStrategyEndOfTurn {
  option (buf.validate.message).cel = {
    id: "eager_lte_eot"
    message: "eager_confidence_threshold must be <= confidence_threshold"
    expression: "this.eager_confidence_threshold <= this.confidence_threshold"
  };

  // Confidence threshold for ending a turn.
  double confidence_threshold = 1 [(buf.validate.field).double = {
    gte: 0
    lte: 1
  }];

  // Eager confidence threshold (must be <= confidence_threshold).
  double eager_confidence_threshold = 2 [(buf.validate.field).double = {
    gte: 0
    lte: 1
  }];

  // Maximum silence duration before forcing end of turn after speech starts.
  google.protobuf.Duration timeout = 3 [(buf.validate.field).duration = {
    gte: {seconds: 0}
    lte: {seconds: 10}
  }];
}

// Configuration for vad.
message SpeechToTextStreamCommitStrategyVad {
  // Silence duration before committing transcript. Must be between 0.3s and 3.0s.
  google.protobuf.Duration silence_threshold = 1 [(buf.validate.field).duration = {
    gte: {nanos: 300000000}
    lte: {seconds: 3}
  }];
  // Voice activity detection sensitivity. Must be between 0.1 and 0.9.
  double vad_threshold = 2 [(buf.validate.field).double = {
    gte: 0.1
    lte: 0.9
  }];
  // Minimum speech duration to consider valid. Must be between 50ms and 2000ms.
  google.protobuf.Duration min_speech_duration = 3 [(buf.validate.field).duration = {
    gte: {nanos: 50000000}
    lte: {seconds: 2}
  }];
  // Minimum silence duration before speech is considered ended. Must be between 50ms and 2000ms.
  google.protobuf.Duration min_silence_duration = 4 [(buf.validate.field).duration = {
    gte: {nanos: 50000000}
    lte: {seconds: 2}
  }];
}

// Response message for AiService.SpeechToTextStream.
message SpeechToTextStreamResponse {
  // Content of this response.
  oneof content {
    option (buf.validate.oneof).required = true;

    // Indicates the user has started speaking a new turn.
    SpeechToTextStreamTurnEvent turn_start = 1;

    // Provides a partial transcript update during an ongoing turn.
    SpeechToTextStreamTurnEvent turn_update = 2;

    // Indicates the model predicts the turn is likely ending (tentative, may be resumed).
    SpeechToTextStreamTurnEvent turn_eager_end = 3;

    // Indicates a previously signaled eager end of turn was incorrect and the turn continues.
    SpeechToTextStreamTurnEvent turn_resumed = 4;

    // Indicates the user's turn has definitively ended with a final transcript.
    SpeechToTextStreamTurnEvent turn_end = 5;

    // Model usage metrics (sent at the end of the stream).
    .malonaz.ai.v1.ModelUsage model_usage = 6;

    // Generation metrics (sent at the end of the stream).
    .malonaz.ai.v1.GenerationMetrics generation_metrics = 7;
  }
}

// Holds transcript events.
message SpeechToTextStreamTurnEvent {
  // Index of the turn this event belongs to, starts at zero.
  int32 turn_index = 1;

  // Transcript for this turn so far.
  string transcript = 2;

  // Confidence score (0.0 to 1.0) that this turn has ended.
  double end_of_turn_confidence = 3;
}
