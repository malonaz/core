syntax = "proto3";

package malonaz.ai.v1;

import "buf/validate/validate.proto";
import "google/protobuf/struct.proto";
import "google/protobuf/timestamp.proto";
import "malonaz/ai/v1/tool.proto";

option go_package = "github.com/malonaz/core/genproto/ai/v1";

// Wrapper message representing any message type in a multi-turn conversation.
// Use this when building conversation histories or streaming message sequences.
message Message {
  option (buf.validate.message).cel = {
    id: "role_matches_message_type"
    message: "role must match message type"
    expression: "(this.role == 1 && has(this.system)) || (this.role == 2 && has(this.assistant)) || (this.role == 3 && has(this.user)) || (this.role == 4 && has(this.tool))"
  };

  // When this message was created.
  google.protobuf.Timestamp create_time = 1;

  // Arbitrary key-value metadata associated with the message.
  map<string, string> metadata = 2;

  // Role of the message sender.
  Role role = 3 [(buf.validate.field).enum = {
    defined_only: true
    not_in: [0]
  }];

  // The specific message type. Exactly one must be set.
  oneof message {
    option (buf.validate.oneof).required = true;

    // A system instruction message.
    SystemMessage system = 10;

    // A user input message.
    UserMessage user = 11;

    // An assistant response message.
    AssistantMessage assistant = 12;

    // A tool result message.
    ToolResultMessage tool = 13;
  }
}

// System message that sets the behavior, context, and instructions for the AI.
// Typically placed at the beginning of a conversation to establish the AI's persona,
// constraints, and response style.
message SystemMessage {
  // The instruction content for the AI system.
  string content = 1 [(buf.validate.field).required = true];
}

// Assistant message representing a response from the AI model.
// Must contain either text content, tool calls, or both.
message AssistantMessage {
  option (buf.validate.message).cel = {
    id: "assistant_requires_content_or_tool_calls"
    message: "AssistantMessage must have either content, structured_content, or at least one tool_call"
    expression: "this.content != '' || has(this.structured_content) || size(this.tool_calls) > 0"
  };

  // Internal reasoning or chain-of-thought generated by the model.
  // Only populated when using models that support extended thinking.
  string reasoning = 1;

  // The text content of the assistant's response.
  // May be empty if the assistant is only making tool calls.
  string content = 2;

  // Structured content extracted from the response when TextToTextConfiguration.extract_json_object is true.
  google.protobuf.Struct structured_content = 3;

  // Tool invocations requested by the assistant.
  // When present, the caller should execute these tools and return results
  // via ToolMessage before continuing the conversation.
  repeated ToolCall tool_calls = 4;
}

// Result of a tool invocation.
// Sent in response to an AssistantMessage that requested tool calls.
message ToolResultMessage {
  // The unique identifier of the tool call this result responds to.
  // Must match the id field from a ToolCall in a preceding AssistantMessage.
  string tool_call_id = 1 [(buf.validate.field).required = true];

  // The result of a tool execution.
  ToolResult result = 2;
}

// User message representing input from a human participant in the conversation.
message UserMessage {
  // The content blocks of the user's input.
  // Supports mixed content types (text, images) in a single message.
  repeated ContentBlock content_blocks = 1 [(buf.validate.field).repeated.min_items = 1];
}

// A block of content within a message.
message ContentBlock {
  // The content type.
  oneof content {
    option (buf.validate.oneof).required = true;

    // Text content.
    string text = 1;

    // Image content.
    ImageBlock image = 2;
  }
}

// An image block within a message.
message ImageBlock {
  option (buf.validate.message).cel = {
    id: "image_block_requires_media_type_for_data"
    message: "media_type is required when using data"
    expression: "!has(this.data) || this.media_type != ''"
  };

  // The image source.
  oneof source {
    option (buf.validate.oneof).required = true;

    // Raw image bytes.
    bytes data = 1;

    // URL to the image. Supports both HTTPS URLs and data URLs
    // (e.g., "data:image/png;base64,...").
    string url = 2;
  }

  // MIME type of the image (e.g., "image/png", "image/jpeg", "image/webp", "image/gif").
  // Required when using `data`, optional when using `url`.
  string media_type = 3;

  // Quality of the image.
  ImageQuality quality = 4 [(buf.validate.field).enum.defined_only = true];
}

// Represents the level of reasoning effort for AI model responses.
// Controls how many internal reasoning tokens the model generates before
// producing its final response. Higher effort yields more thorough reasoning
// at the cost of increased latency and token usage.
enum ReasoningEffort {
  // Unspecified reasoning effort. Should not be used explicitly.
  REASONING_EFFORT_UNSPECIFIED = 0;

  // Default reasoning effort as configured by the platform.
  REASONING_EFFORT_DEFAULT = 1;

  // Low reasoning effort.
  // Prioritizes speed and token efficiency with minimal internal reasoning.
  // Best for simple, straightforward queries.
  REASONING_EFFORT_LOW = 2;

  // Medium reasoning effort.
  // Balances response speed with reasoning thoroughness.
  // Suitable for most general-purpose queries.
  REASONING_EFFORT_MEDIUM = 3;

  // High reasoning effort.
  // Maximizes reasoning depth and accuracy by generating more thinking tokens.
  // Best for complex problems requiring careful analysis.
  // May result in slower responses and higher token consumption.
  REASONING_EFFORT_HIGH = 4;
}

// Represents the role of a message in a multi-turn AI conversation.
enum Role {
  // Used to detect an unset field.
  ROLE_UNSPECIFIED = 0;
  // System message.
  ROLE_SYSTEM = 1;
  // Assistant message.
  ROLE_ASSISTANT = 2;
  // User message.
  ROLE_USER = 3;
  // User message.
  ROLE_TOOL = 4;
}

// Controls the fidelity level for image processing in vision requests.
enum ImageQuality {
  // Unspecified quality. The provider will use its default setting.
  IMAGE_QUALITY_UNSPECIFIED = 0;
  // Automatic quality selection based on image size and content.
  IMAGE_QUALITY_AUTO = 1;
  // Low fidelity processing for faster, cheaper responses.
  IMAGE_QUALITY_LOW = 2;
  // High fidelity processing for detailed image analysis.
  IMAGE_QUALITY_HIGH = 3;
}
